<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>LEC 07</title><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/></head><body><article id="12c2e7d3-01e5-80e4-97b5-d7a5921240bc" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/document_blue.svg"/></div><h1 class="page-title">LEC 07</h1><p class="page-description"></p></header><div class="page-body"><p id="12c2e7d3-01e5-807b-92e5-f156c39d2c27" class=""><strong>Topic: </strong>soft-margin SVM</p><p id="12c2e7d3-01e5-80cd-9d51-f9cf03c3e922" class="">Generalizing hard-margin SVM to non-linearly separable data. </p><figure id="12c2e7d3-01e5-8065-ad99-e778126d07c3" class="image"><a href="LEC%2007/IMG_6FB419184F10-1.jpeg"><img style="width:288px" src="LEC%2007/IMG_6FB419184F10-1.jpeg"/></a></figure><hr id="12c2e7d3-01e5-8092-8f5b-f3cf1cd10430"/><p id="12c2e7d3-01e5-8075-858f-fcd9f8f4b5bc" class=""><strong>Hard vs. Soft Margin</strong></p><figure id="12c2e7d3-01e5-80de-a767-e6c3b7378d96" class="image"><a href="LEC%2007/IMG_3553DE6B2C71-1.jpeg"><img style="width:506.9921875px" src="LEC%2007/IMG_3553DE6B2C71-1.jpeg"/></a></figure><ul id="12c2e7d3-01e5-800d-93a6-f912571b3141" class="bulleted-list"><li style="list-style-type:disc">In hard-margin, we outright dont consider points that are incorrectly classified. </li></ul><ul id="12c2e7d3-01e5-801d-b574-db878a6cf995" class="bulleted-list"><li style="list-style-type:disc">The added term is called <strong>hinge loss</strong><ul id="12c2e7d3-01e5-802c-b89a-e6eb8673e424" class="bulleted-list"><li style="list-style-type:circle">The hyper-parameter <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span><span>﻿</span></span> sets the penalty on margin violations. </li></ul><ul id="12c2e7d3-01e5-80e7-8054-c37056fd79cb" class="bulleted-list"><li style="list-style-type:circle"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>0</mn><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext></mrow><annotation encoding="application/x-tex">C=0 \implies </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6684em;vertical-align:-0.024em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟹</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span></span></span><span>﻿</span></span>no penalty </li></ul><ul id="12c2e7d3-01e5-801e-a1b3-f974abf6ff35" class="bulleted-list"><li style="list-style-type:circle"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi mathvariant="normal">∞</mi><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext></mrow><annotation encoding="application/x-tex">C=\infin \implies</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mord">∞</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟹</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span></span></span><span>﻿</span></span>hard margin SVM</li></ul><figure id="12c2e7d3-01e5-807b-a573-c41ac8abb0ff" class="image"><a href="LEC%2007/IMG_E7DC90430290-1.jpeg"><img style="width:576px" src="LEC%2007/IMG_E7DC90430290-1.jpeg"/></a></figure></li></ul><p id="12c2e7d3-01e5-80af-9fbe-e481418c42a3" class="">Hard margin SVM has high variance (between datasets): </p><figure id="12c2e7d3-01e5-8019-a74f-fbaa7e2f8cd6" class="image"><a href="LEC%2007/IMG_8AD2E14CF990-1.jpeg"><img style="width:288px" src="LEC%2007/IMG_8AD2E14CF990-1.jpeg"/></a><figcaption>The 3 datasets are slightly different. Yet, with hard-margin SVM, they yield very different parameters. Soft-margin SVM would reduce this variance. </figcaption></figure><p id="12c2e7d3-01e5-80e1-b720-f04497ce8716" class=""><strong>Soft SVM as Regularized Regression</strong></p><figure id="12c2e7d3-01e5-8007-be4d-c523219b5e15" class="image"><a href="LEC%2007/IMG_A6493ABE0E32-1_2.jpeg"><img style="width:336px" src="LEC%2007/IMG_A6493ABE0E32-1_2.jpeg"/></a></figure><p id="12c2e7d3-01e5-8017-9ca1-d4d5c9c849bf" class=""><strong>Dual of S.M-SVM</strong></p><ul id="12c2e7d3-01e5-806a-9c63-e3dbdbf53fc3" class="toggle"><li><details open=""><summary>Derivation </summary></details></li></ul><p id="12c2e7d3-01e5-8061-88c8-d62f17a36cdc" class="">Same as the hard-margin dual, with an additional constraint: </p><figure id="12c2e7d3-01e5-801c-8137-d488cde38cdb" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>≤</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">\lambda_i \le C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span></div></figure><p id="12c2e7d3-01e5-802c-947d-f3dbe7bd719d" class=""><em>ie. the feasible region is smaller</em></p><p id="12c2e7d3-01e5-80b0-beb9-fc98d918b5f7" class="">This constraint limits the effect that a support vector could have. </p><ul id="12c2e7d3-01e5-803c-845d-c91e50277b0a" class="bulleted-list"><li style="list-style-type:disc">ie: the size of the weights are regulated</li></ul><p id="12c2e7d3-01e5-8028-991a-f5e94e391289" class=""><strong>Stochastic Gradient Descent on the Primal Objective </strong></p><p id="12c2e7d3-01e5-8092-a754-fd37319d77e9" class="">
</p><p id="12c2e7d3-01e5-80ad-b150-f3dbaf9f887b" class="">
</p><p id="12c2e7d3-01e5-8023-911b-db603645a45f" class="">
</p><p id="12c2e7d3-01e5-8085-9d14-e936d2e558b6" class="">
</p><ul id="1602e7d3-01e5-80ba-9135-fda3f80d2774" class="toggle"><li><details open=""><summary><strong>L07</strong></summary><ul id="12533dc0-63ad-4c34-b3a0-bef3631fa5a5" class="bulleted-list"><li style="list-style-type:disc">Recognize the hinge loss for the soft-SVM problem</li></ul><ul id="1193ca63-21fa-4b74-9665-2b3d260f1019" class="bulleted-list"><li style="list-style-type:disc">Interpret the geometric properties of the soft-SVM decision boundary, including<br/>margin, support vectors, and slack variables.<br/></li></ul><ul id="c9705f19-8c24-4633-b954-62756cf0e7b8" class="bulleted-list"><li style="list-style-type:disc">Describe the effect of hyperparameter C on model performance, generalization,<br/>and the norm of the weights.<br/></li></ul><ul id="d8fc6760-6824-4a6a-9546-db19d91e88a5" class="bulleted-list"><li style="list-style-type:disc">Perform hyperparameter tuning using techniques like cross-validation to optimize<br/>soft-margin SVM parameter.<br/></li></ul><ul id="387281d7-ada1-4467-b838-60aa2b958023" class="bulleted-list"><li style="list-style-type:disc">List the strengths and limitations of algorithms for solving soft-margin SVMs</li></ul></details></li></ul></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>