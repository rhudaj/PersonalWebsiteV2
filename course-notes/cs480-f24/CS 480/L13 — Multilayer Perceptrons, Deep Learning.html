<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>L13 — Multilayer Perceptrons, Deep Learning</title><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/></head><body><article id="13a2e7d3-01e5-8056-9920-d9aeb0cf9815" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/document_blue.svg"/></div><h1 class="page-title">L13 — Multilayer Perceptrons, Deep Learning</h1><p class="page-description"></p></header><div class="page-body"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-80f7-a4e7-c6b0188eae56"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/question-mark_gray.svg"/></div><div style="width:100%"><p id="653d64d7-b04d-4d95-ab07-4332bfa0ebbc" class=""><strong>L13 — To Know</strong></p><hr id="1602e7d3-01e5-807f-b117-d339be11a122"/><ul id="1602e7d3-01e5-8038-b201-f4a33ff167a7" class="toggle"><li><details open=""><summary>Whats the need for learned features.</summary><ul id="1602e7d3-01e5-8033-b2f8-f87a70093914" class="bulleted-list"><li style="list-style-type:disc"><strong>Traditional methods</strong> rely on manually designed features or feature maps based on prior knowledge of the data.</li></ul><ul id="1602e7d3-01e5-809f-a186-d614814394db" class="bulleted-list"><li style="list-style-type:disc"><strong>Neural networks</strong> learn features/feature maps directly from the data, which allows the network to discover patterns and solve problems where it&#x27;s not clear what features would be helpful.</li></ul><p id="1602e7d3-01e5-80fd-ae2a-ed1a6faa3fab" class="">
</p></details></li></ul><ul id="1602e7d3-01e5-8090-9fdf-f328908bd17b" class="toggle"><li><details open=""><summary>State the universal approximation theorem of a multilayer perceptron (MLP) including the the conditions (nonlinear activation, sufficient depth) and caveats (potentially infinite width) to achieve the associated guarantee.</summary><ul id="1602e7d3-01e5-8002-8b75-f1e3ff5447ac" class="bulleted-list"><li style="list-style-type:disc">A feedforward network with 1<strong> input layer, one hidden layer, and a non-linear activation function</strong> can approximate any continuous function, provided that:<ul id="0e463241-64ca-469f-b805-36e9844d8849" class="bulleted-list"><li style="list-style-type:circle">The hidden layer has <strong>enough units</strong>.</li></ul><ul id="2a04370d-cc98-4f08-9d84-741eda6464de" class="bulleted-list"><li style="list-style-type:circle">The activation function is <strong>nonlinear and continuous</strong>.</li></ul></li></ul><ul id="1602e7d3-01e5-800f-a46e-ec3085af13bf" class="bulleted-list"><li style="list-style-type:disc"><strong>Caveat</strong>: More units (width) leads to better precision for approximating the function, potentially requiring infinite width to capture the function perfectly.</li></ul><ul id="1602e7d3-01e5-8058-831f-f1ad5b66d819" class="bulleted-list"><li style="list-style-type:disc"><strong>Generalization</strong>: extends to multiple hidden layers (<strong>deep networks</strong>).</li></ul></details></li></ul><ul id="1602e7d3-01e5-8049-8281-e67562d72595" class="toggle"><li><details open=""><summary>How do you use chain rule to compute the gradient with respect to the parameters.</summary><ul id="1602e7d3-01e5-8052-8a59-c75ce4e1ace0" class="bulleted-list"><li style="list-style-type:disc">To know the loss at a shallower layer, you need to know the loss from the layers ahead of it.</li></ul><ul id="1602e7d3-01e5-8025-b8c2-f5ddc84fa746" class="bulleted-list"><li style="list-style-type:disc">The chain rule is used to calculate the gradient with respect to the parameters in each layer by propagating gradients backwards through the network, starting from the output layer.</li></ul><ul id="1602e7d3-01e5-8054-a9de-fe5952a5517f" class="bulleted-list"><li style="list-style-type:disc">The <strong>chosen activation function</strong> plays a large role in finding the gradient.</li></ul></details></li></ul><ul id="1602e7d3-01e5-802c-ae7c-f4d413f72be4" class="toggle"><li><details open=""><summary>List and describe theoretical issues (vanishing gradients, model complexity) that must be addressed to apply an MLP to real data.</summary><ul id="1602e7d3-01e5-8074-850b-f8d52960fb82" class="bulleted-list"><li style="list-style-type:disc"><strong>Vanishing Gradients</strong>: The gradient of the activation function (e.g., sigmoid) may &quot;vanish&quot; as you propagate them backwards. This can slow down or stall training, particularly in deep networks.<ul id="69bc3256-1d43-4cb7-9e31-213a275066d4" class="bulleted-list"><li style="list-style-type:circle">Sigmoid is more prone to vanishing gradients.</li></ul><ul id="d3e86903-74fa-4d83-be16-04f8f360749a" class="bulleted-list"><li style="list-style-type:circle">ReLU&#x27;s derivative remains constant when propagating so long as the neuron is active.</li></ul></li></ul><ul id="1602e7d3-01e5-8014-88c6-f626fdaa88a8" class="bulleted-list"><li style="list-style-type:disc"><strong>Model Complexity</strong>: MLPs have many parameters, especially in deep networks. This increases the risk of overfitting.<ul id="0f565199-9b28-4b7c-a50e-1946bb5113ce" class="bulleted-list"><li style="list-style-type:circle">The number of parameters can be far more than the number of training samples.</li></ul></li></ul></details></li></ul><ul id="1602e7d3-01e5-802e-ae97-cc24869d406c" class="toggle"><li><details open=""><summary>Describe the architecture and parameterization of a MLP.</summary><ul id="1602e7d3-01e5-806d-8b0d-f0c1a752f30e" class="bulleted-list"><li style="list-style-type:disc">MLPs consist of multiple layers of nodes:<ul id="ff5b3a11-5c6e-4947-81c2-c1ff2d752423" class="bulleted-list"><li style="list-style-type:circle"><strong>Input layer</strong>: Receives input features.</li></ul><ul id="0275b12b-bb82-4133-b017-347e170dfc40" class="bulleted-list"><li style="list-style-type:circle"><strong>Hidden layers</strong>: Apply a projection matrix and a non-linear function to generate new features.</li></ul><ul id="6989e7a4-c902-4de1-8099-4bba5b87b17a" class="bulleted-list"><li style="list-style-type:circle"><strong>Output layer</strong>: Produces the final predictions, typically with a learnable bias.</li></ul></li></ul><ul id="1602e7d3-01e5-80ae-8bb0-e6fbb6d3f24e" class="bulleted-list"><li style="list-style-type:disc"><strong>Parameters</strong>: Each layer has its own projection matrix and bias terms.<ul id="f020a68d-afc4-410b-8684-35b2df865b5f" class="bulleted-list"><li style="list-style-type:circle">For an input-hidden layer, each node receives a weighted combination of the input features.</li></ul><ul id="19d1197f-93a6-4ec9-9c94-431553d015ad" class="bulleted-list"><li style="list-style-type:circle">The connections between each node are associated with a weight.</li></ul><ul id="4fcfcdaf-9d85-42f9-a370-c132e41e68a9" class="bulleted-list"><li style="list-style-type:circle">Each hidden unit is a weighted sum of the input features.</li></ul></li></ul><ul id="1602e7d3-01e5-80be-8cbc-d46f26763271" class="bulleted-list"><li style="list-style-type:disc">A non-linear function is applied after each weighted sum.</li></ul><ul id="1602e7d3-01e5-8058-bc57-e31801a98423" class="bulleted-list"><li style="list-style-type:disc">A <strong>softmax function</strong> (non-linear) can be used at the output layer for multi-class classification.</li></ul></details></li></ul><ul id="1602e7d3-01e5-8080-9064-c88d76c2e3d6" class="toggle"><li><details open=""><summary><strong>strategies to reduce overfitting</strong></summary><ul id="1602e7d3-01e5-80cd-a082-fb6fd6e3a8a1" class="bulleted-list"><li style="list-style-type:disc"><strong>Early Stopping (Checkpointing)</strong>: Save model parameters periodically during training and stop when the error on a validation set stops decreasing.</li></ul><ul id="1602e7d3-01e5-8030-8ae6-eeff61445dd0" class="bulleted-list"><li style="list-style-type:disc"><strong>Weight Decay</strong>: Impose a penalty for large weights during gradient descent (similar to ridge regression).</li></ul><ul id="1602e7d3-01e5-80cc-a6a2-f394cdabb6e9" class="bulleted-list"><li style="list-style-type:disc"><strong>Data Augmentation</strong>: Create fake data by transforming existing data to make the model invariant to transformations. This is not suitable for all types of data (e.g. digit recognition).</li></ul><ul id="1602e7d3-01e5-80b0-bc2a-f41ba99aa392" class="bulleted-list"><li style="list-style-type:disc"><strong>Dropout</strong>: Randomly drop out nodes during training iterations to prevent dependencies of weights from any one node.</li></ul><ul id="1602e7d3-01e5-8029-b8f5-dee4bf994106" class="bulleted-list"><li style="list-style-type:disc"><strong>Normalization</strong>: Normalization techniques improve gradient flow by normalizing the input to hidden layers, which leads to better optimization.</li></ul></details></li></ul><ul id="1602e7d3-01e5-8021-8868-d8904026fe8a" class="toggle"><li><details open=""><summary>Recommend either a traditional ML algorithm or a neural network depending on the nature of the problem, the data, and specific goals.</summary><ul id="1602e7d3-01e5-80e6-9ab1-effae605baf5" class="bulleted-list"><li style="list-style-type:disc"><strong>Traditional ML</strong>: Use when you have good prior knowledge of the data, well-defined features, or if the dataset is small. Typically the # of parameters will be equal to the dimensionality of the data, and fewer than the number of training examples.</li></ul><ul id="1602e7d3-01e5-80a8-be8d-e497d54c73a2" class="bulleted-list"><li style="list-style-type:disc"><strong>Neural Networks</strong>: Use when the number of parameters is greater than the number of training examples, and when it&#x27;s unclear what features would help solve the problem. Also when you have a lot of data, and you want to automatically learn features from the data itself.</li></ul></details></li></ul></div></figure><hr id="1602e7d3-01e5-8026-a743-fb94cf9f2c76"/><h3 id="13a2e7d3-01e5-80b8-9fcc-f61ffcd48ba1" class=""><strong>Motivation</strong></h3><p id="13a2e7d3-01e5-80b7-8cb5-e24aa4e8af88" class="">Perceptron only worked for linearly separable data. Then using feature maps, we could represent non-linear data. Either way, we’re working with features from the original input data, or mapping them. <em><strong>We need to know enough about the data to decide what features are important. </strong></em></p><ul id="1602e7d3-01e5-8014-b4ee-f216de45404f" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Example</mark></summary><p id="1602e7d3-01e5-80c8-a2fe-d9ec14d84683" class="">Each pixel is a feature (796 total).There’s no indication of a feature map that we could design to tell these classes apart (distinct digits) or what set of features would allow us to solve the problem. </p><figure id="13a2e7d3-01e5-8095-85bb-e7ad455c691c" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.46.51.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.46.51.png"/></a><figcaption>Not clear what features would help us solve the problem. </figcaption></figure></details></li></ul><h3 id="13a2e7d3-01e5-806d-b019-d9702bb3785f" class=""><strong>Neural Network</strong></h3><ul id="13a2e7d3-01e5-8086-91d8-d18a9ee0d98d" class="bulleted-list"><li style="list-style-type:disc">what? Learns the feature-map. </li></ul><ul id="1602e7d3-01e5-801c-8876-d5bbb6c7bac3" class="bulleted-list"><li style="list-style-type:disc">why? allows us to discover patterns (most important features)</li></ul><figure id="13a2e7d3-01e5-803b-b800-d30f924dba9d" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.55.17.png"><img style="width:576px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.55.17.png"/></a></figure><ul id="13a2e7d3-01e5-805c-9c46-c6969f0bd593" class="bulleted-list"><li style="list-style-type:disc">The box contains <strong>hidden units</strong>. They each receive a weighted combination of each input feature. So the output is in feature-mapped space, where we can learn a <strong>linear classifier</strong>. </li></ul><ul id="1602e7d3-01e5-80ab-9b1d-c2c0f934298c" class="bulleted-list"><li style="list-style-type:disc">Formally, a feature map <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span></span><span>﻿</span></span> is created by the inner product of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="double-struck">d</mi></msup></mrow><annotation encoding="application/x-tex">x\in \mathbb{R^d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> and some <strong>projection matrix, </strong><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">V\in \mathbb{R}^{d\times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> to get some output in the new features space: <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="double-struck">m</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R^m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></li></ul><ul id="1602e7d3-01e5-80f1-90ff-cbbf0326a4a2" class="bulleted-list"><li style="list-style-type:disc">Each hidden unit is a weighted sum of the input features, where <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> indicates the weighting that point <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> has on the hidden unit <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. </li></ul><figure id="1602e7d3-01e5-80b8-a599-cd9433c4e4b0" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.57.43.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.57.43.png"/></a></figure><ul id="1602e7d3-01e5-80e3-9e3e-e70a95e17e91" class="bulleted-list"><li style="list-style-type:disc">(Problem) The resulting predictor, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, is a <strong>linear combination</strong> <strong>of the input features</strong> (in terms of the weights <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">u_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, which combines the input weights, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span></span><span>﻿</span></span> and the output weights, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span></span><span>﻿</span></span><ul id="1602e7d3-01e5-801f-935c-c01908c15690" class="bulleted-list"><li style="list-style-type:circle">⇒ <strong>no “expressive power” gained</strong></li></ul></li></ul><figure id="1602e7d3-01e5-8055-a7f5-c58e2c0d3bf1" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.00.12.png"><img style="width:480px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.00.12.png"/></a></figure><ul id="1602e7d3-01e5-801a-ba44-f8f9b8f3ed9e" class="bulleted-list"><li style="list-style-type:disc">Cant just learn a projection matrix, need non-linearity in order to learn <strong>useful features</strong></li></ul><ul id="1602e7d3-01e5-800e-bf42-c2da04121296" class="bulleted-list"><li style="list-style-type:disc">(Solution) apply a <strong>set of </strong><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span><span>﻿</span></span><strong> non-linear basis functions </strong>to each (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span><span>﻿</span></span>) hidden unit outputs ⇒ output is non-linear in terms of the input features</li></ul><figure id="1602e7d3-01e5-8038-b0c0-cb979d1ed3de" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.04.08.png"><img style="width:432px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.04.08.png"/></a><figcaption>Sample functions. Note: the x-axis should be ‘t’ not ‘z’ </figcaption></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-80f0-a970-f56e0208e307"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="d3172738-259a-4c1a-baf6-92252bc8899f" class=""><mark class="highlight-red"><strong>Feedforward Network </strong></mark></p><hr id="1602e7d3-01e5-80c8-a36b-eb49b6d4e3a9"/><ul id="1602e7d3-01e5-80ed-8d8f-e0da47b07a96" class="bulleted-list"><li style="list-style-type:disc">No loops or feedback paths.</li></ul><ul id="1602e7d3-01e5-805b-8c50-c5d21e4546d3" class="bulleted-list"><li style="list-style-type:disc">Primarily used for tasks like <span style="border-bottom:0.05em solid">regression</span>, <span style="border-bottom:0.05em solid">classification</span>, and <span style="border-bottom:0.05em solid">function approximation</span>.</li></ul><ul id="1602e7d3-01e5-8027-82ed-c458e89d21db" class="bulleted-list"><li style="list-style-type:disc">Each layer transforms its input into a new feature space.</li></ul></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13a2e7d3-01e5-80a4-8672-c43757d99d48"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="7a4e3b75-db4a-4b2d-91f8-82cf1e23fe71" class=""><mark class="highlight-red"><strong>Universal Approximation Theorem</strong></mark></p><hr id="13a2e7d3-01e5-80a9-a733-e02e2c21ecd0"/><p id="1602e7d3-01e5-804d-80b0-c4494c700589" class="">A feedforward N.N with a <span style="border-bottom:0.05em solid">linear output layer</span> and <span style="border-bottom:0.05em solid">at least one hidden layer</span> can approximate any continous function <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="double-struck">d</mi></msup><mo>→</mo><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="double-struck">k</mi></msup></mrow><annotation encoding="application/x-tex">f: \mathbb{R^d} \rarr \mathbb{R^k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8452em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8452em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathbb mtight">k</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> on a <span style="border-bottom:0.05em solid">closed and bounded subspace</span> of  <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="double-struck">d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R^d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, provided:</p><ol type="1" id="1602e7d3-01e5-80b2-a35b-fbcf80e5fa60" class="numbered-list" start="1"><li>the hidden layer is <span style="border-bottom:0.05em solid">sufficiently wide</span></li></ol><ol type="1" id="1602e7d3-01e5-807e-907b-f5fb85d51778" class="numbered-list" start="2"><li>the <span style="border-bottom:0.05em solid">activation function</span> is <span style="border-bottom:0.05em solid">nonlinear and continous</span></li></ol><p id="13a2e7d3-01e5-8058-8dc1-d2641106c474" class="">
</p><figure id="13a2e7d3-01e5-80ad-934c-e242fc60d864" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.08.26.png"><img style="width:480px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.08.26.png"/></a></figure><p id="13a2e7d3-01e5-8075-b66b-f7abb0aca524" class="">More units ⇒ more precision for approximating a function. </p></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-8028-a346-ed246194b312"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/question-mark_gray.svg"/></div><div style="width:100%"><p id="95216c43-83bc-4a74-ba02-c6f195d53978" class=""><strong>Note — “Linear Output Layer” </strong></p><ul id="1602e7d3-01e5-800a-9885-cd02b2554898" class="bulleted-list"><li style="list-style-type:disc">Means “LINEAR in terms of the activations from the previous layer”</li></ul><ul id="1602e7d3-01e5-80a1-8ffc-d39dc80b2fc5" class="bulleted-list"><li style="list-style-type:disc">Ensures a clear separation of roles: hidden layers handle nonlinearity, while the output layer combines these representations <em><mark class="highlight-gray">(complexity is shifted to the hidden layers)</mark></em></li></ul></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-8009-80c1-d2d9bfd4afa3"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/question-mark_gray.svg"/></div><div style="width:100%"><p id="be0e2017-d408-4927-9dbd-bd2da98bd240" class=""><strong>Note — Activation Functions</strong></p><ul id="1602e7d3-01e5-8070-9998-ecd6237206ab" class="bulleted-list"><li style="list-style-type:disc">Different layers can use different activation functions, and even within the same layer, neurons can have distinct activation functions. For example:</li></ul></div></figure><h3 id="13a2e7d3-01e5-80be-b023-d9686284e8a8" class="">Deep Network</h3><p id="1602e7d3-01e5-80bb-bae7-eda7211fd0d0" class=""><em><mark class="highlight-gray"><strong>Generalize N.N (e.g. MLP) to multiple layers (mappings)</strong></mark></em></p><figure id="58bf239a-a3e5-4c80-b827-e594dbb2b32f" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.52.35.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_16.52.35.png"/></a></figure><ul id="13a2e7d3-01e5-805d-a7c1-cc060ba4c03b" class="bulleted-list"><li style="list-style-type:disc"><strong>Depth </strong><em><mark class="highlight-gray">(of network)</mark></em><strong>:</strong> # hidden layers(2)<ul id="1602e7d3-01e5-8083-b003-df79601e02d9" class="bulleted-list"><li style="list-style-type:circle"><em><mark class="highlight-gray">Each layer has its own projection matrix. </mark></em></li></ul></li></ul><ul id="13a2e7d3-01e5-80bd-940f-f0363558435b" class="bulleted-list"><li style="list-style-type:disc"><strong>Width </strong><em><mark class="highlight-gray">(of a specific layer)</mark></em><strong>:</strong> # units in the layer</li></ul><ul id="1602e7d3-01e5-8027-9e7b-ca5da3b022a6" class="bulleted-list"><li style="list-style-type:disc"><strong>Output Layer Functions: </strong></li></ul><ul id="1602e7d3-01e5-8091-aeab-c407f07e14bd" class="bulleted-list"><li style="list-style-type:disc"><strong>Functions on output layer: </strong><ul id="268301d3-ecec-4733-bb53-18b70c20751b" class="bulleted-list"><li style="list-style-type:circle">Typically add a learnable <strong>bias </strong></li></ul><ul id="68de50fb-1a07-4f75-b3c6-2ba65df9d411" class="bulleted-list"><li style="list-style-type:circle"><strong>Sigmoid</strong> for classification</li></ul><ul id="89f762d4-db8c-4ff0-8902-0a0ed43490f5" class="bulleted-list"><li style="list-style-type:circle"><strong>Softmax</strong> for multi-class classification </li></ul><ul id="ce126ba6-bff1-405f-92d5-89c386c7b7d7" class="bulleted-list"><li style="list-style-type:circle">Could <strong>generalize </strong>to learn multiple functions at once <em><mark class="highlight-gray">(see below)</mark></em></li></ul><figure id="13a2e7d3-01e5-80eb-a395-c9105439f57b" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.12.59.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-10_at_17.12.59.png"/></a><figcaption>This N.N learns multiple functions at once. </figcaption></figure></li></ul><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-80ae-a560-e6c454055fb1"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/question-mark_gray.svg"/></div><div style="width:100%"><p id="c663393c-3923-4b41-8018-b2cea717178d" class=""><strong>Varying Depth vs. Width</strong></p><ol type="1" id="1602e7d3-01e5-8062-b527-faa42f9e2992" class="numbered-list" start="1"><li><strong>Increasing Depth</strong><ul id="1602e7d3-01e5-805a-a872-f78e0bee52a4" class="bulleted-list"><li style="list-style-type:disc"><strong>What it does: </strong>represents <span style="border-bottom:0.05em solid">deeply compositional</span> or <span style="border-bottom:0.05em solid">highly structured (hierarchical) functions</span></li></ul><ul id="1602e7d3-01e5-803a-a875-f254cc698ba2" class="bulleted-list"><li style="list-style-type:disc"><strong>Effect:</strong> Each layer learns progressively higher-level <em>abstractions</em> of the input features</li></ul><ul id="1602e7d3-01e5-805a-93a2-ecdbcd0d31cd" class="bulleted-list"><li style="list-style-type:disc"><strong>Trade-offs:</strong><ul id="1602e7d3-01e5-80f3-ac59-f45635684309" class="bulleted-list"><li style="list-style-type:circle">More efficient at representing <em>*some</em> functions with fewer parameters.</li></ul><ul id="1602e7d3-01e5-80ce-bd89-fd44db49fa39" class="bulleted-list"><li style="list-style-type:circle">Harder to train/optimize due to vanishing/exploding gradients</li></ul></li></ul></li></ol><ol type="1" id="1602e7d3-01e5-809b-8d1d-eea412062920" class="numbered-list" start="2"><li><strong>Increasing Width</strong><ul id="1602e7d3-01e5-8086-abd2-c68f7c9dbb1d" class="bulleted-list"><li style="list-style-type:disc"><strong>What it does:</strong> increases the <span style="border-bottom:0.05em solid">capacity</span> of a layer to capture details in the input (ie: memorize more details of the function it approximates). </li></ul><ul id="1602e7d3-01e5-80fa-b487-d98e8bc5670a" class="bulleted-list"><li style="list-style-type:disc"><strong>Effect: </strong><mark class="highlight-default">By increasing the width, the network can “span” the space of continuous functions over the domain </mark><em><mark class="highlight-gray">(U.A.T)</mark></em></li></ul><ul id="1602e7d3-01e5-8062-a6ac-ed73822ccd0e" class="bulleted-list"><li style="list-style-type:disc"><strong>Trade-offs:</strong><ul id="1602e7d3-01e5-80a0-8d36-ddd88f2339b6" class="bulleted-list"><li style="list-style-type:circle">Might need too many neurons to represent a complex function.</li></ul><ul id="1602e7d3-01e5-8064-a02d-cae870110403" class="bulleted-list"><li style="list-style-type:circle">Overfitting. </li></ul></li></ul></li></ol><hr id="1602e7d3-01e5-80eb-b498-d9453d2095fe"/><p id="1602e7d3-01e5-80d0-9acb-c510f74585b1" class=""><em><mark class="highlight-gray"><strong>Why does U.A.T. Focus on Width?</strong></mark></em></p><ul id="1602e7d3-01e5-803b-a051-f01a32c2c677" class="bulleted-list"><li style="list-style-type:disc"><em><mark class="highlight-gray">Depth is not required because with enough neurons in one layer, any function can theoretically be approximated. However, this does not consider efficiency or practicality.</mark></em></li></ul></div></figure><h2 id="13a2e7d3-01e5-8069-9883-d875390148f3" class="">Training N.N’s </h2><p id="13e2e7d3-01e5-80b3-87be-f150c77f03c1" class="">Minimize the expected loss, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>argmin</mtext><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mo stretchy="false">[</mo><msub><mi>l</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{argmin}_\theta \mathbb{E}[l_\theta(x,y)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord text"><span class="mord">argmin</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.242em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)]</span></span></span></span></span><span>﻿</span></span>. </p><p id="1602e7d3-01e5-80b4-b50a-dbe429dbeeb8" class=""><strong>Problem 1: </strong>many paramters</p><ul id="1602e7d3-01e5-8081-9275-ded6d61c5713" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Example</mark></summary><figure id="13f2e7d3-01e5-8045-8bea-d3a712d8f6cc" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.00.16.png"><img style="width:240px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.00.16.png"/></a></figure><p id="13f2e7d3-01e5-80ff-9502-e89dafb44533" class=""><strong>31 total parameters in hidden layer: </strong></p><ul id="13f2e7d3-01e5-801b-a88d-cadf3d3022e8" class="bulleted-list"><li style="list-style-type:disc">Input-hidden layer: 4 x 5 = 20 weights</li></ul><ul id="13f2e7d3-01e5-80c9-84f4-e975d7fd2a21" class="bulleted-list"><li style="list-style-type:disc">Hidden layer: 1 bias per neuron (with ReLU)  = 5</li></ul><ul id="13f2e7d3-01e5-80a8-a881-c2aa69b5eeeb" class="bulleted-list"><li style="list-style-type:disc">Hidden-output: 5 weights + 1 bias </li></ul></details></li></ul><p id="13f2e7d3-01e5-80c5-bdfc-e5a15a744563" class=""><strong>Problem 2: </strong>not a convex optimization problem</p><ul id="1602e7d3-01e5-806d-b0f1-c1e8584b1b55" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Example</mark></summary><p id="1602e7d3-01e5-8040-a35f-d35f9bdb803e" class="">Consider the simplest example</p><figure id="1602e7d3-01e5-8020-b342-de877a67f8c0" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.02.39.png"><img style="width:60px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.02.39.png"/></a></figure><p id="1602e7d3-01e5-80df-8d1f-d7ed658a9ccd" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>W</mi><mn>2</mn></msub><mi>X</mi></mrow><annotation encoding="application/x-tex">Y=W_1W_2X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></span><span>﻿</span></span></p><p id="1602e7d3-01e5-80be-9039-d4b91c019ae9" class="">With 1 input, 1 hidden neuron, 1 output. It’s trained to compute the identity function (input = output). </p><p id="1602e7d3-01e5-8070-84b7-ed6358b6d992" class="">For <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_i,y_i)=(1,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span></p><p id="1602e7d3-01e5-80e4-8bc4-ea3555f1eabb" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>W</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L=(1-W_1W_2)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="1602e7d3-01e5-80ff-bc52-f15637e35ce2" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><msub><mi>W</mi><mn>1</mn></msub><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\implies W_1W_2=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟹</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span></p><p id="1602e7d3-01e5-8045-8d75-ed0d461fa944" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><mfrac><mn>1</mn><msub><mi>W</mi><mn>2</mn></msub></mfrac></mrow><annotation encoding="application/x-tex">W_2= \frac{1}{W_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span></p><p id="1602e7d3-01e5-8049-ab31-e2c9468897e1" class="">There are infinite solutions for <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>W</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>W</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(W_1,W_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> which is not a convex optimization problem, even for such a simple problem with only 2 parameters. </p><p id="1602e7d3-01e5-8050-9645-fc0ebb354fe3" class="">Hence, with 31 parameters, WTF. </p><figure id="1602e7d3-01e5-8023-8824-e2ede3b4fa76" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.06.51.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.06.51.png"/></a><figcaption>F*** THAT </figcaption></figure></details></li></ul><h3 id="13f2e7d3-01e5-8074-9a35-ceebf2073642" class=""><strong>Loss Gradient for MLP </strong></h3><ul id="1602e7d3-01e5-80db-9a9f-c2c90d869322" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Ex 1 — no hidden layer, linear</mark></summary><blockquote id="1602e7d3-01e5-804d-a9e5-e33bcecdaeff" class=""><em><strong>Key Insight: larger error ⇒ decrease weight </strong></em></blockquote><figure id="1602e7d3-01e5-8061-9e61-d600bb276e21" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.12.13.png"><img style="width:240px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.12.13.png"/></a></figure><ol type="1" id="1602e7d3-01e5-8086-abb1-ecfcd9b7b9f3" class="numbered-list" start="1"><li>Select squared loss function (half for convenience: <p id="3cab233b-c083-4299-99d6-53ad6e3854b2" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L=\frac{1}{2}(\hat{y}-y)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="f128fa45-133f-412c-98b1-36843f604436" class="">Where: <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>X</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">z=w_1X_1+w_2X_2+b_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p></li></ol><ol type="1" id="1602e7d3-01e5-8082-9ee2-c9c6acd8f18c" class="numbered-list" start="2"><li>Compute gradient (w’ respect to each weight): <figure id="f756a2ee-dc4a-4e71-820a-f7eb5fb42a4a" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.13.09.png"><img style="width:240px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.13.09.png"/></a></figure></li></ol></details></li></ul><ul id="13f2e7d3-01e5-80ca-aebf-e0d0531bc714" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Ex 2 — no hidden layer, non-linear</mark></summary><figure id="13f2e7d3-01e5-80de-aa13-ed5eaa708f07" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.14.48.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.14.48.png"/></a></figure><p id="13f2e7d3-01e5-8060-adb0-e0d8fcd315dd" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>X</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">z=w_1X_1+w_2X_2+b_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="13f2e7d3-01e5-8062-ba49-d7545baa57ce" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{y}= f(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> (non-linear) </p><p id="13f2e7d3-01e5-80f6-934a-caae665e17e0" class="">Gradient of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span>: </p><figure id="13f2e7d3-01e5-8034-b1a2-e6347c49bd0c" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.16.42.png"><img style="width:288px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.16.42.png"/></a></figure></details></li></ul><ul id="1602e7d3-01e5-807e-b74b-d0630da85e61" class="toggle"><li><details open=""><summary><mark class="highlight-purple">Ex 2 — 1 hidden layer, non-linear</mark></summary><blockquote id="1602e7d3-01e5-80d6-b2e7-d18e9df149ba" class=""><em><strong>Key Insight: in order to know the loss at a shallower layer, you need to know the loss from the layers ahead of it. </strong></em></blockquote><p id="13f2e7d3-01e5-8021-a896-c4b74cb85258" class="">Now, with a hidden layer: </p><figure id="13f2e7d3-01e5-807f-9da9-d71366af53c7" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.17.21.png"><img style="width:240px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.17.21.png"/></a></figure><p id="13f2e7d3-01e5-80bf-9258-e5a1cdfada4b" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{y}= f(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> </p><p id="13f2e7d3-01e5-80f4-baf2-fa71432d2b16" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>w</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mi>a</mi><mo>+</mo><msub><mi>b</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">z=w_{out}a+b_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span><div class="indented"><p id="13f2e7d3-01e5-8033-bd89-db259d3df37f" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>h</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a=h(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span><div class="indented"><p id="13f2e7d3-01e5-802f-aed4-cf60e1b331f7" class=""><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>X</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t=w_1X_1+w_2X_2+b_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p></div></p></div></p><p id="13f2e7d3-01e5-8021-bf26-d945da537daa" class="">Gradient of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span>: </p><figure id="13f2e7d3-01e5-8014-9827-eeedbb5591a8" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/c5783506-e34b-4e3c-8b29-ba70c3a91150.png"><img style="width:336px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/c5783506-e34b-4e3c-8b29-ba70c3a91150.png"/></a></figure></details></li></ul><p id="1602e7d3-01e5-80ee-8411-eaf9754ed035" class=""><em><strong>Key Insights: </strong></em></p><ul id="1602e7d3-01e5-806a-bd53-fdd65cbcd3b3" class="bulleted-list"><li style="list-style-type:disc"><em>larger error ⇒ decrease weight </em></li></ul><ul id="1602e7d3-01e5-8067-b626-e120834be5dd" class="bulleted-list"><li style="list-style-type:disc"><em>in order to know the loss at a layer, you need to know the loss from the layers ahead of it. </em></li></ul><hr id="13f2e7d3-01e5-8035-a2b9-e8391094cef0"/><p id="13f2e7d3-01e5-805f-8e77-f4eac4875fab" class="">The chosen activation function plays a big role in finding the gradient. </p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-80e4-aae9-d622b94273f5"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark_gray.svg"/></div><div style="width:100%"><p id="ad4c79dd-8e70-4e44-ac73-76d462e0f0eb" class=""><strong>Vanishing Gradient Problem</strong></p><hr id="1602e7d3-01e5-8044-afd1-fb016d6312e8"/><p id="1602e7d3-01e5-801c-afdb-e796ed32b5a2" class="">The gradient of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span></span><span>﻿</span></span> (e.g. ReLU, sigmoid) may “vanish” as you propagate them backwards. More likely for a <span style="border-bottom:0.05em solid">deep-network</span></p><ul id="1602e7d3-01e5-8055-861f-c121ab01058a" class="bulleted-list"><li style="list-style-type:disc">Sigmoid: more prone (since it has a part with low slope).</li></ul><ul id="1602e7d3-01e5-8049-96ee-ddc99de744aa" class="bulleted-list"><li style="list-style-type:disc">ReLU: derivative remains constant when propagating. so long as the neuron is active (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">z&gt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span><span>﻿</span></span> on the plot). </li></ul><figure id="13f2e7d3-01e5-80de-a0e8-daab70543034" class="image" style="text-align:center"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.30.39.png"><img style="width:336px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.30.39.png"/></a><figcaption>the derivative of the sigmoid where the slope is minimum will be very small. ReLU for <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">z&gt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span><span>﻿</span></span> will have a constant derivative </figcaption></figure></div></figure><hr id="13f2e7d3-01e5-809e-9b2a-f7033c25bb6c"/><h2 id="1602e7d3-01e5-80d8-aa1c-d33f5d3a8a68" class="">Overfitting &amp; Regularization</h2><h3 id="1602e7d3-01e5-80d2-a401-fd56c0e0ff32" class=""><strong>MLP ⇒ many parameters ⇒ risk of overfitting</strong></h3><p id="13f2e7d3-01e5-80fa-9447-c63e26dca3a7" class="">For <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span><span>﻿</span></span> parameters, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> training examples and <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span><span>﻿</span></span> features</p><ul id="13f2e7d3-01e5-80f5-9eb5-d80abe293dde" class="bulleted-list"><li style="list-style-type:disc">Classical ML: </li></ul><figure id="13f2e7d3-01e5-804d-9360-c209878baedb" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo>≈</mo><mi>d</mi><mo>&lt;</mo><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">p \approx d &lt;&lt;n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6776em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span></div></figure><ul id="13f2e7d3-01e5-8041-8693-c306b6fc828e" class="bulleted-list"><li style="list-style-type:disc"><em>Neural Networks:</em></li></ul><figure id="13f2e7d3-01e5-8085-bba0-d59fbb2cbf71" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mo>&gt;</mo><mi>n</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">p &gt;&gt;nd</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span></span></span></span></span></div></figure><p id="13f2e7d3-01e5-803f-9bf4-c0b2d66e6c13" class=""><em><mark class="highlight-default"><mark class="highlight-default_background">⇒ Many parameters (often more than the # samples) ⇒ a N.N could essentially </mark></mark></em><em><mark class="highlight-default"><mark class="highlight-default_background"><span style="border-bottom:0.05em solid">memorize the whole training set</span></mark></mark></em><em><mark class="highlight-default"><mark class="highlight-default_background">. Such a complex model is prone to overfitting. </mark></mark></em></p><hr id="13f2e7d3-01e5-8050-b4a4-f9dcbfc644c7"/><h3 id="13f2e7d3-01e5-8078-a85c-fcfdcd7a8d4f" class=""><strong>Regularization Techniques </strong></h3><p id="13f2e7d3-01e5-8002-951c-cf964950ced7" class="">See slides for math behind each technique. </p><p id="13f2e7d3-01e5-80b3-ad45-c2c716e70797" class=""><strong>#1 — Checkpointing (Early Stopping)</strong></p><ul id="13f2e7d3-01e5-8094-bf42-e5b3e991f228" class="bulleted-list"><li style="list-style-type:disc">While doing your gradient descent iterations, periodically save the model parameters and test the model on a validation set. Stop while the error on this set stops decreasing. </li></ul><figure id="13f2e7d3-01e5-80be-9601-f3c827436035" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.41.43.png"><img style="width:384px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.41.43.png"/></a><figcaption>training error decreases consistently. Test set loss plateaus and maybe increases. </figcaption></figure><p id="13f2e7d3-01e5-80c4-8f04-f7f53d820748" class=""><strong>#2 — Weight Decay</strong></p><ul id="13f2e7d3-01e5-80fd-83a6-d2a5a8e5646e" class="bulleted-list"><li style="list-style-type:disc">Ridge regression DURING gradient descent. So now the weight update step takes imposes a penalty for large weights. </li></ul><p id="13f2e7d3-01e5-806d-a6b5-e52c873fd645" class=""><strong>#3 — Data Augmentation </strong></p><ul id="13f2e7d3-01e5-801f-a1a2-cc0fcc3b06cd" class="bulleted-list"><li style="list-style-type:disc">Train it on more data by creating fake data (e.g. for image recognition, take one image and transform it it different ways, makes model <strong>invariant</strong> to transformations). Depends on what is acceptable. This would not work for digit recognition (e.g. 6 vs. 9).  </li></ul><figure id="13f2e7d3-01e5-800f-a4d9-cf95f4eb11ce" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.48.27.png"><img style="width:240px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_19.48.27.png"/></a></figure><p id="13f2e7d3-01e5-8062-8c04-db761609ec6f" class=""><strong>#4 — Dropout</strong></p><ul id="13f2e7d3-01e5-80d2-a3bd-f449423464ad" class="bulleted-list"><li style="list-style-type:disc">Randomly drop-out &amp; retain nodes during training iterations (w’ some probability). If its dropped, it wont contribute to weight updates for that iteration. This helps discourages dependencies of the weights from any one node. </li></ul><p id="13f2e7d3-01e5-8093-8342-d7b35e11c41a" class=""><strong>#5 — Normalization</strong></p><figure id="13f2e7d3-01e5-8009-bffd-fdd7bc5b8455" class="image"><a href="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_20.00.56.png"><img style="width:576px" src="L13%20%E2%80%94%20Multilayer%20Perceptrons,%20Deep%20Learning%2013a2e7d301e580569920d9aeb0cf9815/Screenshot_2024-11-14_at_20.00.56.png"/></a></figure><p id="13f2e7d3-01e5-8029-8a80-dfe978f20190" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>