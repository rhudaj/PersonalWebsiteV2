<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>07 — Relational Data</title><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/></head><body><article id="13e2e7d3-01e5-80af-aeec-dc875f7d4e64" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/folder_purple.svg"/></div><h1 class="page-title">07 — Relational Data</h1><p class="page-description"></p></header><div class="page-body"><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0">Motivation</summary><div class="indented"><p id="13f2e7d3-01e5-80b3-84bd-e583722c8f1a" class=""><em><mark class="highlight-gray"><strong>Why we need to represent Relational Algebra in MapReduce</strong></mark></em></p><p id="13e2e7d3-01e5-80d8-972d-ef9e95b56661" class=""><strong>Background: </strong></p><p id="13e2e7d3-01e5-80da-9192-c5c0195e6173" class="">Programs used to be simple files. Today you have big programs with a frontend and backend. The backend usually revolves around a <strong>database</strong>. Even before computers, businesses still relied on <strong>data</strong>. </p><p id="13e2e7d3-01e5-801c-9637-d2c6e0507d9f" class="">Two groups of people interact with database. <strong>Analysts </strong>want to gather insights from the database (from the backend). <strong>Users </strong>want to interact with the app, which involves interacting with the database indirectly. These are two unique <strong>database workloads</strong>: </p><figure id="13e2e7d3-01e5-80e8-8d04-d33a043b6f3f" class="image"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_13.47.31.png"><img style="width:707.96875px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_13.47.31.png"/></a></figure><figure class="block-color-default callout" style="white-space:pre-wrap;display:flex" id="13e2e7d3-01e5-80de-b4e2-f3d656635932"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="6ea17566-337e-4ded-a50e-54f3582041a1" class=""><strong>Database Workloads </strong></p><hr id="13e2e7d3-01e5-804b-bbb3-d992f6433ad1"/><p id="13e2e7d3-01e5-8024-af21-f63990e597a1" class=""><strong>OLTP </strong></p><ul id="13e2e7d3-01e5-804b-904e-ee1e4a0aa43a" class="bulleted-list"><li style="list-style-type:disc">Online Transaction Processing</li></ul><ul id="13e2e7d3-01e5-80fd-a044-d98edb66063a" class="bulleted-list"><li style="list-style-type:disc">Most Applications:<ul id="13e2e7d3-01e5-80b9-86b8-eaac4dd4697d" class="bulleted-list"><li style="list-style-type:circle">E-Commerce, Banking, Reddit, etc. </li></ul></li></ul><ul id="13e2e7d3-01e5-8069-8858-e096af91677e" class="bulleted-list"><li style="list-style-type:disc">User Facing: Must be fast, low latency, concurrent (many users)</li></ul><ul id="13e2e7d3-01e5-804b-831d-f6a683967feb" class="bulleted-list"><li style="list-style-type:disc">Tasks: small set of common queries </li></ul><ul id="13e2e7d3-01e5-80c3-b9cd-fb3480b9105e" class="bulleted-list"><li style="list-style-type:disc">Access: random reads, small writes</li></ul><p id="13e2e7d3-01e5-8036-9d14-fc164d7c760a" class=""><strong>OLAP</strong></p><ul id="13e2e7d3-01e5-807e-9812-c7b65305954a" class="bulleted-list"><li style="list-style-type:disc">BI and Data Mining </li></ul><ul id="13e2e7d3-01e5-807e-9278-d97369865a91" class="bulleted-list"><li style="list-style-type:disc">Back-End: Batch workloads, low<br/>concurrency <br/></li></ul><ul id="13e2e7d3-01e5-8054-b367-d046db131e30" class="bulleted-list"><li style="list-style-type:disc">Tasks: Complex Analytics (Ad Hoc) </li></ul><ul id="13e2e7d3-01e5-801a-8363-d833c198e994" class="bulleted-list"><li style="list-style-type:disc">Access: Full Table Scans, Big Data</li></ul><hr id="13e2e7d3-01e5-8086-ab24-e32eae8a291e"/><p id="13e2e7d3-01e5-8037-b6ef-f0ee835006ab" class="">Note: </p><p id="13e2e7d3-01e5-8092-addb-fb0c13ca872f" class="">Some of the OLAP stuff ends up user facing…in a way.  e.g. on Facebook, finding friends for you is a long and difficult process but runs in the background.  Every so often (whenever the batch finishes) the front end can be updated with new suggestions.</p></div></figure><p id="13e2e7d3-01e5-803f-a73c-d2b88bb10564" class="">
</p><p id="13e2e7d3-01e5-8002-aafe-ecfc07d0dfdd" class=""><mark class="highlight-red_background"><strong>Problem</strong></mark><div class="indented"><p id="13e2e7d3-01e5-8012-8282-eefb6e1b9a50" class="">When using a single database that the web-app and analysts both connect to, the database can only handle so much workload. If an analyst is running a query over the entire database, the users will experience slowdown (OLAP consumes resources). If many users are doing actions at once, the analysts will have to wait longer. </p><p id="13e2e7d3-01e5-8084-b181-fd0d4fee0a82" class="">These 2 forms of access are fundamentally different. <strong>A single DB can’t be tuned to accomodate both access patterns</strong>. </p></div></p><p id="13e2e7d3-01e5-8015-b887-c27a4576a19c" class=""><mark class="highlight-teal_background"><strong>Solution</strong></mark></p><h2 id="13e2e7d3-01e5-80cc-85ee-da6d2009d087" class=""><strong>Data warehouse </strong></h2><p id="13e2e7d3-01e5-8052-94cb-fa58ed102f57" class="">The warehouse is the original (entire) database, tuned for OLAP queries. </p><p id="13e2e7d3-01e5-8041-8fa6-d3e17f28711c" class="">The backend contains a database tuned for OLTP queries. This database is usually smaller, containing only the required information from the warehouse. The data from the warehouse is <span style="border-bottom:0.05em solid">periodically</span> <em>copied </em>to the DB (so the analysts can see the changes made by the users). The process is called <strong>ETL</strong></p><figure id="13e2e7d3-01e5-80cd-80a8-da9b4d320f27" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_13.50.42.png"><img style="width:384px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_13.50.42.png"/></a></figure><p id="13e2e7d3-01e5-80f8-8d4d-d30562f7e36e" class=""><strong>ETL </strong></p><ul id="13e2e7d3-01e5-80c2-833c-ccede8044af5" class="bulleted-list"><li style="list-style-type:disc"><strong>Extract: </strong>copy over new /updated rows </li></ul><ul id="13e2e7d3-01e5-80a7-9cbe-c400ac3e98be" class="bulleted-list"><li style="list-style-type:disc"><strong>Transform: </strong>since the analysts might use/define the data differently <ul id="13e2e7d3-01e5-8025-a471-e74527686ab8" class="bulleted-list"><li style="list-style-type:circle">clean &amp; validate the data (the analysts might have a different standard for what is “good” data). </li></ul><ul id="13e2e7d3-01e5-80c9-bf52-cb2ca8daa728" class="bulleted-list"><li style="list-style-type:circle">schema conversion (they might also store the data differently) </li></ul><ul id="13e2e7d3-01e5-8041-9877-d887eb01976f" class="bulleted-list"><li style="list-style-type:circle">(maybe) field transformation (i.e. change the datatype)</li></ul></li></ul><ul id="13e2e7d3-01e5-809e-8f6f-ca7bf7b05d07" class="bulleted-list"><li style="list-style-type:disc"><strong>Load</strong></li></ul><p id="13e2e7d3-01e5-8013-9a2c-f68721d01463" class=""><strong>When to do ETL? </strong><div class="indented"><p id="13e2e7d3-01e5-80e5-bfe4-e66fe108faee" class="">Depends on what the analysts need. Could be: </p><ul id="13e2e7d3-01e5-807f-91e5-c0800b1e4c2e" class="bulleted-list"><li style="list-style-type:disc">Rolling basis (i.e. every X updates)</li></ul><ul id="13e2e7d3-01e5-808a-ac5b-ccb4e72ff73a" class="bulleted-list"><li style="list-style-type:disc">Daily batch </li></ul></div></p><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><mark class="highlight-purple"><strong>Example</strong></mark></summary><div class="indented"><p id="13e2e7d3-01e5-80c4-84a7-f47eab1749ba" class=""><strong>Typical OLTP Schema </strong></p><ul id="13e2e7d3-01e5-8063-a15a-fda025d99b78" class="bulleted-list"><li style="list-style-type:disc"><code>customers</code> sign in. they have your info like credit card.</li></ul><ul id="13e2e7d3-01e5-8062-b76c-cad3bc3a1847" class="bulleted-list"><li style="list-style-type:disc"><code>orders</code> have line items, each references is an <code>inventory</code> product.</li></ul><figure id="13e2e7d3-01e5-807e-bcac-e316e8de5d49" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.01.38.png"><img style="width:240px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.01.38.png"/></a><figcaption>Foreign key → Primary Key </figcaption></figure><p id="13e2e7d3-01e5-8015-811f-d8adfe4a7f0e" class=""><strong>Typical OLAP Schema </strong></p><p id="13e2e7d3-01e5-80c9-ba0f-e5cd98d9370e" class=""><strong>“Star” Schema </strong></p><ul id="13e2e7d3-01e5-8015-8566-ee0c41a5256c" class="bulleted-list"><li style="list-style-type:disc">Center – Fact Table; contains all elements that DO NOT relate to the other rows.  </li></ul><ul id="13e2e7d3-01e5-80ef-bbd5-da6836e56809" class="bulleted-list"><li style="list-style-type:disc">Points – Dimension Tables; any values that DO relate / correlate with other rows will “dimension” attributes – foreign keys to a dimension table.</li></ul><figure id="13e2e7d3-01e5-8077-bba8-cf776daaf315" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.02.54.png"><img style="width:240px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.02.54.png"/></a></figure><p id="13e2e7d3-01e5-8004-9d81-d3dc63116a65" class="">Here, the central fact is selling an object (corresponds to line items from OrderLine). Each row is 1 sale of 1+ things.</p><p id="13e2e7d3-01e5-8033-a5d8-dababc604de3" class="">The able contains from the stuff in the backend DB and live data from stores. </p><p id="13e2e7d3-01e5-80ac-a7d9-cec4bc566557" class="">When you sell a Widget, that goes into <code>Fact_Sales</code>. Things that are unique to the sale will go in this table (e.g. the number of items sold). The fact that it was a widget will be a foreign key into the product Dimension table. Which store it was bought at will be a foreign key into the store Dimension table. Same with which customer, which order this sale was a part of, what day it was sold on.  </p><p id="13e2e7d3-01e5-80d8-a61a-c442001c459f" class=""><strong>Why STAR Schema? </strong></p><ul id="13e2e7d3-01e5-8068-ac5e-dfb6ca4bad98" class="bulleted-list"><li style="list-style-type:disc">Lets us do common OLAP operations efficiently. Many OLAP queries are about getting chunks (whether an individual cell, a row/column, a plane, etc). </li></ul><ul id="13e2e7d3-01e5-80d4-aa37-e22ec8951875" class="bulleted-list"><li style="list-style-type:disc">Not as great for <em><strong>ad-hoc</strong></em><em> </em>queries. We can only answer questions based on what we know, not what we don’t know. <ul id="13e2e7d3-01e5-80ae-b509-ff5cc92ac9b5" class="bulleted-list"><li style="list-style-type:circle">You cannot tune a database for a query that doesn’t yet exist (Something you don’t even know you, you cannot write the query). </li></ul><ul id="13e2e7d3-01e5-80a4-a4e1-e9f49bf6f430" class="bulleted-list"><li style="list-style-type:circle">You can, however, tune it for a fairly broad class of queries. </li></ul></li></ul><p id="13e2e7d3-01e5-8008-963f-e66234a8a5e9" class="">
</p><p id="13e2e7d3-01e5-8016-9f8e-ee73c8d2f318" class="">
</p><p id="13e2e7d3-01e5-8058-8e4d-ccb7f7b7666a" class="">
</p><p id="13e2e7d3-01e5-80bf-b47a-d2be53732719" class="">
</p></div></details><p id="13e2e7d3-01e5-8043-97b5-c6ba5355bf00" class="">
</p><p id="13e2e7d3-01e5-800a-8845-df9a351bcc9f" class=""><strong>Multiple Backend DB’s </strong></p><p id="13e2e7d3-01e5-80ce-9e23-db8389ef7aeb" class="">The data warehouse can pull from multiple backend databases (e.g. multiple apps). That’s why it’s a warehouse.  </p><figure id="13e2e7d3-01e5-80f7-80ca-cb111045d66d" class="image"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.11.45.png"><img style="width:288px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.11.45.png"/></a></figure><hr id="13e2e7d3-01e5-803e-afc2-f38dc642c93c"/><p id="13e2e7d3-01e5-80f9-a081-e07abfba0f98" class=""><mark class="highlight-red_background"><strong>Problem</strong></mark><div class="indented"><p id="13e2e7d3-01e5-802c-94f2-db070a476e48" class="">In modern times, theres a 3rd type of access: people want to do <strong>data mining </strong>in order to do predictive things (i.e. machine learning). e.g. you want to know what is going to sell next quarter, not what sold the most last quarter. </p><p id="13e2e7d3-01e5-802e-96ad-ece7c41952f5" class="">As a result people want a lot of data.<strong> </strong></p><p id="13e2e7d3-01e5-8099-9242-cdb8a0f6a6fc" class="">As a result, <strong>data generation rate exceeds data ingestion rate</strong>. </p></div></p><p id="13e2e7d3-01e5-801a-9846-cb24b6710347" class=""><mark class="highlight-teal_background"><strong>Solution</strong></mark><div class="indented"><p id="13e2e7d3-01e5-808b-8368-c148e7d118d4" class="">Data storage is now cheap. Now companies store whatever data they can get, in case they might need it. </p></div></p><p id="13e2e7d3-01e5-8031-8211-c5f4d5f92336" class=""><mark class="highlight-red_background"><strong>Problem</strong></mark><div class="indented"><p id="13e2e7d3-01e5-8079-9737-c3c12dd81067" class="">Database don’t scale well. i.e. they scale vertically (expensive). </p></div></p><p id="13e2e7d3-01e5-806a-ac8b-eaf5a301a0f4" class=""><mark class="highlight-teal_background"><strong>Solution</strong></mark> <div class="indented"><p id="13e2e7d3-01e5-80f9-b47e-c02672776fd6" class="">Why not use Hadoop since clusters scales horizontally. </p></div></p><figure class="block-color-default callout" style="white-space:pre-wrap;display:flex" id="13e2e7d3-01e5-80ab-9cf3-f1e66827a345"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="4727b48a-aa4d-4024-8057-67687ac430d6" class=""><strong>Database Pros &amp; Cons </strong></p><div id="13e2e7d3-01e5-80e5-a867-dacc0c441554" class="column-list"><div id="8e41f6ea-a4ba-4e72-99ea-767c2bac7fb2" style="width:50%" class="column"><p id="13e2e7d3-01e5-80c6-a694-c297acba3c96" class=""><strong>Databases are great… </strong></p><ul id="13e2e7d3-01e5-8062-b73c-e6d1a971f551" class="bulleted-list"><li style="list-style-type:disc">If your data has structure</li></ul><ul id="13e2e7d3-01e5-802d-9a72-dc514640351f" class="bulleted-list"><li style="list-style-type:disc">And you know that structure </li></ul><ul id="13e2e7d3-01e5-80aa-a3a8-f58c564e11fa" class="bulleted-list"><li style="list-style-type:disc">Your data are clean</li></ul><ul id="13e2e7d3-01e5-8099-888a-f05a64931e3e" class="bulleted-list"><li style="list-style-type:disc">You know queries ahead of time (⇒ The Star Schema)</li></ul></div><div id="add6daa2-bcab-4874-b37b-3c60b50f4dcc" style="width:50%" class="column"><p id="13e2e7d3-01e5-8048-8087-fe01c7f060a5" class=""><strong>Databases are not great… </strong></p><ul id="13e2e7d3-01e5-804f-945f-d2c53b30a90b" class="bulleted-list"><li style="list-style-type:disc">If your data has little structure</li></ul><ul id="13e2e7d3-01e5-8099-be1c-d65a724d89f2" class="bulleted-list"><li style="list-style-type:disc">Or you don’t know the structure</li></ul><ul id="13e2e7d3-01e5-80b1-aec7-e936927476e3" class="bulleted-list"><li style="list-style-type:disc">data needs cleaning</li></ul><ul id="13e2e7d3-01e5-80a2-99dd-e9f056d5cdaf" class="bulleted-list"><li style="list-style-type:disc">Doing data mining / ML (don’t know what your looking for) </li></ul></div></div></div></figure><p id="13e2e7d3-01e5-8078-ac8a-f1fe73c27bcb" class=""><strong>Migrating to Hadoop (HIVE)? </strong></p><p id="13e2e7d3-01e5-80de-aeae-c5cc503ad7d2" class="">Instead of a giant database for a warehouse, why not use <strong>Hadoop</strong> (i.e. a cluster which is designed with Big Data in mind). And instead of trying to load data from HDFS files into the database, why not directly run queries directly against HDFS files, so now ETL is: extract &amp; load onto HDFS and transform with a MapReduce job. </p><figure id="13e2e7d3-01e5-8059-b2bd-d545f9b67197" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.16.40.png"><img style="width:480px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.16.40.png"/></a></figure><p id="13e2e7d3-01e5-80b1-84d0-ccd43e5fb6b0" class="">The problem know SQL, not MapReduce. Facebook introduced <strong>HIVE</strong> as a solution to that, which lets you write SQL queries to access HDFS.  </p><figure id="13e2e7d3-01e5-80de-ba27-c65ae92683bb" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.22.33.png"><img style="width:480px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_14.22.33.png"/></a></figure><hr id="13e2e7d3-01e5-80e1-88c8-ee6c12397e68"/><p id="13e2e7d3-01e5-80d4-a2a1-e0b138a70f8d" class=""><strong>BI Analytics </strong>want to do a variety of things: </p><ul id="13f2e7d3-01e5-80cf-ad7a-ea6c49431316" class="bulleted-list"><li style="list-style-type:disc">generate reports (STAR schema works fine)</li></ul><ul id="13f2e7d3-01e5-8016-b2dd-e828c76fe482" class="bulleted-list"><li style="list-style-type:disc">create monitoring dashboards (e.g. what are users doing, whats the response time). It’s <strong>live data</strong>.  </li></ul><ul id="13f2e7d3-01e5-80d6-8184-d7dd87c719b2" class="bulleted-list"><li style="list-style-type:disc"><strong>ad hoc</strong> analyses<ul id="13f2e7d3-01e5-80f0-b676-efe1da30ff02" class="bulleted-list"><li style="list-style-type:circle">descriptive — extract a description of the data</li></ul><ul id="13f2e7d3-01e5-80bd-a7eb-db483f517aef" class="bulleted-list"><li style="list-style-type:circle">predictive — extract a model of the data that will predict the future </li></ul></li></ul><hr id="13f2e7d3-01e5-808e-85b0-fff82e4cfd9a"/><p id="13f2e7d3-01e5-8041-a8b1-cba451abcf64" class="">Advantages of Hadoop over RDBMS </p><ul id="13f2e7d3-01e5-80da-a153-e3e0d803ae88" class="bulleted-list"><li style="list-style-type:disc">No schemas (more freedom). Dont need schema for a full table scan. </li></ul><ul id="13f2e7d3-01e5-807f-bc73-dcf38e4c36a5" class="bulleted-list"><li style="list-style-type:disc">Flexible: can use HIVE or directly write M.R code.</li></ul><ul id="13f2e7d3-01e5-8015-9b22-d09e00562d45" class="bulleted-list"><li style="list-style-type:disc">HDFS is designed for quickly loading data (e.g. good for live data). </li></ul><p id="13f2e7d3-01e5-80d9-9589-e3a2bc277735" class=""><strong>Important to note: </strong>this is not replacing a database. Hadoop is not a relational database / <strong>not a data warehouse.</strong> It’s a <strong>data lake</strong>. </p><p id="13f2e7d3-01e5-80cb-ba20-d30e0f4c75eb" class=""><strong>“Data Lake”</strong></p><ul id="13f2e7d3-01e5-804e-a712-cae85507a1e6" class="bulleted-list"><li style="list-style-type:disc">Relational and non-relational data from many sources (curated and raw)</li></ul><ul id="13f2e7d3-01e5-802c-9aee-ec21adf39a5f" class="bulleted-list"><li style="list-style-type:disc">No Schema </li></ul><ul id="13f2e7d3-01e5-8067-a08e-db6cdee20aec" class="bulleted-list"><li style="list-style-type:disc">Low-Cost Storage </li></ul><ul id="13f2e7d3-01e5-80fc-8cc8-f4b06c70b97c" class="bulleted-list"><li style="list-style-type:disc">Useful for: Data Scientists, Data Developers, Business Analysts (curated data only)</li></ul><p id="13f2e7d3-01e5-8023-b3bb-d76ea43797e5" class=""><strong>Final Result </strong></p><figure id="13f2e7d3-01e5-802b-ad90-fb0c26a53601" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.20.06.png"><img style="width:384px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.20.06.png"/></a><figcaption>We still have the data warehouse for some queries, where using it would be much faster.</figcaption></figure><p id="13f2e7d3-01e5-80f6-a6ed-dd54a8674007" class=""><strong>How it all works</strong></p><figure id="13f2e7d3-01e5-8047-a049-e15530a17bf9" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.21.43.png"><img style="width:336px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.21.43.png"/></a></figure><p id="13f2e7d3-01e5-8038-925e-c87f74c9347e" class="">Example (word count): </p><ul id="13f2e7d3-01e5-80f2-9589-e062af6c26e3" class="bulleted-list"><li style="list-style-type:disc">join both files together by words.</li></ul><figure id="13f2e7d3-01e5-8096-9b65-e3fd92ebbcae" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.22.26.png"><img style="width:384px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-14_at_21.22.26.png"/></a><figcaption>“word” | word count for file a | word count for file b </figcaption></figure><ul id="13f2e7d3-01e5-80a6-8fac-db113a198ecc" class="bulleted-list"><li style="list-style-type:disc">Behind the scenes, the SQL is<strong> compiled and transformed into MapReduce code</strong></li></ul><ul id="13f2e7d3-01e5-80f0-a1c7-d2d305514f67" class="bulleted-list"><li style="list-style-type:disc">The rest of this lecture is figuring out how to do that </li></ul></div></details><h1 id="13f2e7d3-01e5-8016-8209-efe0c6c0aab0" class="">Relational Algebra (in Map Reduce)</h1><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Selection (</strong><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></span><span>﻿</span></span><strong>)</strong></summary><div class="indented"><p id="1432e7d3-01e5-8072-8915-c6b22fe71a4e" class="">Filtering rows in a dataset based on a condition. </p><p id="1432e7d3-01e5-80d6-9264-e70e0d97680d" class=""><strong>In SQL: </strong><code>WHERE</code>  </p><p id="1432e7d3-01e5-80f4-8a05-c43dca612195" class=""><strong>In MapReduce</strong></p><p id="1432e7d3-01e5-80f0-8a38-c9d819986aed" class="">Single <code>mapper</code> </p><ul id="1432e7d3-01e5-803e-a80f-e42a1745aa6a" class="bulleted-list"><li style="list-style-type:disc">No reduce step: Each row can be independently evaluated for the condition, and no grouping/combining is needed</li></ul><ul id="1472e7d3-01e5-80f0-97a3-f8da5a42c656" class="bulleted-list"><li style="list-style-type:disc">Selected rows are written directly to the output.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-8076-9af6-c6978e96d9c6" class="code"><code class="language-Python"># Note: If its a text file, first parse it and convert to right formats

def map(rowID, row):
		# Only emit rows that satisfy the condition
		if filterCondition(row):
				emit(row)</code></pre><p id="1432e7d3-01e5-807f-ad1e-d8d297cf8806" class=""><strong>Performance: </strong></p><ul id="1432e7d3-01e5-809f-9519-c6f8a176b58c" class="bulleted-list"><li style="list-style-type:disc">The operation performs as fast as HDFS can load the data into the mappers (since there is no need for shuffling or sorting between the map and reduce stages), making it dependent on the data loading speed rather than computation.</li></ul><ul id="1432e7d3-01e5-8012-aa55-c334e3eb0102" class="bulleted-list"><li style="list-style-type:disc">Selection can be combined with other map-side operations (e.g. projection) to further optimize the pipeline.</li></ul><p id="1432e7d3-01e5-8043-8862-da82fdce4258" class=""><strong>Notes: </strong></p><ul id="1432e7d3-01e5-8074-8e25-f9590bf9e451" class="bulleted-list"><li style="list-style-type:disc">Only operators that are map-side only can be pipelined in. </li></ul><p id="1442e7d3-01e5-8095-a52e-e10906b580d9" class="">
</p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Projection (</strong><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span><span>﻿</span></span><strong>)</strong></summary><div class="indented"><p id="1432e7d3-01e5-8086-bb25-d7691ebf2bfb" class="">Selecting specific columns from a dataset and discarding the rest.</p><p id="1432e7d3-01e5-8018-84a1-f9801f9f980f" class=""><strong>In SQL</strong></p><p id="1432e7d3-01e5-8058-80e1-f843517057f1" class="">“SELECT … FROM …” </p><figure id="1432e7d3-01e5-80b6-a126-f101e09a2adb" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.32.47.png"><img style="width:288px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.32.47.png"/></a><figcaption>Keep only the squares and circles from each row (Project each row into lower dimensional space). </figcaption></figure><p id="1432e7d3-01e5-8014-aa40-c73b89d52e4f" class=""><strong>In MapReduce: </strong></p><p id="1432e7d3-01e5-8028-bd49-c77acebdf8f8" class="">Mapper </p><ul id="1432e7d3-01e5-807b-8919-e951f478e19c" class="bulleted-list"><li style="list-style-type:disc">Transforms each tuple (row): a new tuple with only the desired columns.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-8009-9cea-d3f55c1b8ae6" class="code"><code class="language-Python">def map(rowID, row):
    # Assuming `row` is a list or an array of values
    # Define which columns to project (e.g., columns 1 and 3 in zero-indexed format)
    projection_columns = [1, 3]

    # Project the row into a lower-dimensional space
    projected_row = [row[i] for i in projection_columns]

    # Emit the row ID and the projected row
    emit(rowID, projected_row)</code></pre><p id="1432e7d3-01e5-808d-8e99-c9406d5e1368" class=""><strong>Performance: </strong></p><ul id="1432e7d3-01e5-801a-8fa7-c7f79af86f5b" class="bulleted-list"><li style="list-style-type:disc">Same as <em>selection (involves processing each row independently and does not require grouping or shuffling across nodes) </em></li></ul><p id="1432e7d3-01e5-80ed-943c-d07ae17b18a2" class=""><strong>Notes: </strong></p><ul id="1432e7d3-01e5-8084-a462-d2cdfe2b3051" class="bulleted-list"><li style="list-style-type:disc">The projection operation does not require a reduce step because it operates on individual rows independently. </li></ul><ul id="1432e7d3-01e5-8005-be6a-c32409f00fea" class="bulleted-list"><li style="list-style-type:disc">After projection, the positions of the remaining columns may not match their original positions. It’s essential to track the mapping between the old column indices and the new ones to correctly interpret the output later and/or to ensure downstream processes are aware of the new schema.</li></ul><ul id="1432e7d3-01e5-80e5-b746-ddc27c677899" class="bulleted-list"><li style="list-style-type:disc">Only operators that are map-side only can be pipelined in. </li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Rename (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span></span><span>﻿</span></span>)</summary><div class="indented"><p id="1432e7d3-01e5-802d-88eb-cb75cd423c9d" class=""><strong>SQL: “</strong>SELECT (colName newName) FROM …”</p><p id="1432e7d3-01e5-80d4-bc23-fb79fb4955be" class="">Renaming userID as u doesn’t matter at the MapReduce level. MapReduce just sees tuples. It doesn’t care what columns are called. </p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Union (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∪</mo></mrow><annotation encoding="application/x-tex">\cup</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5556em;"></span><span class="mord">∪</span></span></span></span></span><span>﻿</span></span>)</summary><div class="indented"><p id="1432e7d3-01e5-800d-bc00-cadbc27d9042" class="">Combines rows from two datasets into a single dataset</p><p id="1432e7d3-01e5-8088-afc4-d8c822270429" class=""><strong>In SQL</strong></p><p id="1432e7d3-01e5-80ef-9a55-c0cd950e379a" class="">(SELECT ….) <code>UNION</code> (SELECT ….)</p><figure id="1432e7d3-01e5-8065-b5dc-cebf8680d235" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.39.45.png"><img style="width:288px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.39.45.png"/></a></figure><p id="1432e7d3-01e5-8034-82b2-f397314e0c48" class=""><strong>In MapReduce</strong></p><ul id="1432e7d3-01e5-8032-9a08-cfaa610fbd77" class="bulleted-list"><li style="list-style-type:disc">Multiple Inputs: Both datasets are treated as separate inputs, and each is processed by its own mapper. Hadoop’s <code>MultipleInputs</code> class supports this functionality by allowing multiple files to serve as inputs to the MapReduce job.</li></ul><ul id="1432e7d3-01e5-80c1-8340-ec8205614178" class="bulleted-list"><li style="list-style-type:disc">Mapper: simply reads the rows from the datasets and emits them without any additional processing.</li></ul><ul id="1432e7d3-01e5-8033-a710-dce913e3b7cd" class="bulleted-list"><li style="list-style-type:disc">No Reducer Needed: Since rows are only appended and not transformed or deduplicated (as in <code>UNION ALL</code>), there is no need for a reduce phase.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-80cd-aa1d-cdda6c9a489a" class="code"><code class="language-Python"># If you have two files, File1 and File2:
#   1. Assign a separate mapper to each file.
#   2. Emit rows directly from both mappers.

# Mapper for File1
def map_file1(rowID, row):
    emit(rowID, row)

# Mapper for File2
def map_file2(rowID, row):
    emit(rowID, row)</code></pre><p id="1432e7d3-01e5-80ba-964a-c9ecf19fdcc3" class=""><strong>Performance </strong></p><ul id="1432e7d3-01e5-800e-8b16-eb3166f564f6" class="bulleted-list"><li style="list-style-type:disc">The use of multiple mappers ensures that both datasets are processed in parallel, improving performance.</li></ul><ul id="1432e7d3-01e5-8084-a077-f73d276ae84b" class="bulleted-list"><li style="list-style-type:disc">Since no keys need to be shuffled between mappers and reducers, the operation is lightweight.</li></ul><p id="1432e7d3-01e5-804a-95a9-e67456549a8f" class=""><strong>Notes</strong></p><ul id="1432e7d3-01e5-8087-9892-d49cd483c8d1" class="bulleted-list"><li style="list-style-type:disc">Union can be combined with other map-side operations (selection, projection) allowing for efficient multi-operation pipelines.</li></ul><ul id="1432e7d3-01e5-8068-9a75-e0d161396406" class="bulleted-list"><li style="list-style-type:disc">Ensure that both input datasets have the same schema (e.g., the same number of columns and data types), as required by the union operation.</li></ul><ul id="1432e7d3-01e5-80e3-bbf2-fcd930817504" class="bulleted-list"><li style="list-style-type:disc">If you want to remove duplicate rows (as in SQL <code>UNION</code>), you need an additional reduce step to group rows and remove duplicates.</li></ul><ul id="1432e7d3-01e5-8092-a846-c79d9b19bbca" class="bulleted-list"><li style="list-style-type:disc">Union does not guarantee any specific order in the output. If ordering is required, a subsequent sort step is needed.</li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Difference (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo></mrow><annotation encoding="application/x-tex">-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span></span></span></span></span><span>﻿</span></span>)</summary><div class="indented"><p id="1432e7d3-01e5-8066-9550-c28f45535326" class="">The difference operation A - B outputs all rows in A that are NOT in B. </p><p id="1432e7d3-01e5-80b6-8dd5-eca04b7e4955" class=""><strong>In SQL</strong> </p><p id="1432e7d3-01e5-80cb-a4e2-cede7e16b834" class="">(SELECT ….) <code>MINUS</code> (SELECT ….) </p><figure id="1432e7d3-01e5-8008-a20c-f1143113c151" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.41.40.png"><img style="width:288px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_12.41.40.png"/></a></figure><p id="1432e7d3-01e5-804a-b069-fd3db6036a88" class=""><strong>MapReduce: </strong></p><ul id="1432e7d3-01e5-80e3-93ca-e8c180939ab0" class="bulleted-list"><li style="list-style-type:disc">Involves multiple steps (reducer and mapper), including tagging rows by their origin, grouping rows, and comparing them within a reducer.</li></ul><ul id="1432e7d3-01e5-8072-8fe2-d15c5fe22276" class="bulleted-list"><li style="list-style-type:disc">Mappers<ul id="1432e7d3-01e5-8023-8f62-fd6a5b5645d4" class="bulleted-list"><li style="list-style-type:circle">Use the <code>MultipleInputs</code> class to process A and B, with separate mappers.</li></ul><ul id="1432e7d3-01e5-803e-b64a-ef52fd565862" class="bulleted-list"><li style="list-style-type:circle">For A: Emit ((row, 1), null), for B: Emit ((row, 2), null)<ul id="1432e7d3-01e5-8068-94e4-edb8349c82a2" class="bulleted-list"><li style="list-style-type:square">key: the row itself, tagged with an identifier (1 for A, 2 for B)</li></ul><ul id="1432e7d3-01e5-800c-a883-fa97a0bc5c2b" class="bulleted-list"><li style="list-style-type:square">Value: Not used</li></ul></li></ul></li></ul><ul id="1432e7d3-01e5-803c-b96d-dab064d029ae" class="bulleted-list"><li style="list-style-type:disc">Partioner (shuffle)<ul id="1432e7d3-01e5-800f-ab0a-e988a46a3358" class="bulleted-list"><li style="list-style-type:circle">Ensure all instances of the same row (from A and B) are sent to the same reducer. This involves hashing all the columns of the row (ignoring the tag).</li></ul></li></ul><ul id="1432e7d3-01e5-807a-a849-ccd7495abf89" class="bulleted-list"><li style="list-style-type:disc">Sorting<ul id="1432e7d3-01e5-806d-97f3-c155c90b6cc8" class="bulleted-list"><li style="list-style-type:circle">The framework ensures that within a reducer, rows from <code>B</code> (tag = <code>2</code>) appear before rows from <code>A</code> (tag = <code>1</code>) for the same keys. </li></ul></li></ul><ul id="1432e7d3-01e5-8084-9ec3-dd1e1a01806c" class="bulleted-list"><li style="list-style-type:disc">Reducer<ul id="1432e7d3-01e5-8098-9d78-f4a6f66addfa" class="bulleted-list"><li style="list-style-type:circle">Processes rows partitioned by their composite key:<ul id="1432e7d3-01e5-8093-8da2-d80c62b4388d" class="bulleted-list"><li style="list-style-type:square">Retains the last row from B (if present).</li></ul><ul id="1432e7d3-01e5-80a6-b961-feb445c9cadc" class="bulleted-list"><li style="list-style-type:square">Emits rows from A only if they do not match the row from B.</li></ul></li></ul></li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-80c7-96cf-f57559bb98e8" class="code"><code class="language-Python">def map_A(_, row):
		# Tag row with 1 (LHS)
    emit((row, 1), None)

def map_B(_, row):
    # Tag row with 2 (RHS)
    emit((row, 2), None)

def reduce(composite_key, values):
    # composite_key = (row, tag), values = list of occurrences
    row, tag = composite_key
    if tag == 2:  # Process dataset B
        # Store the last RHS row (we only need the most recent one for comparison)
        global last_rhs
        last_rhs = row
    elif tag == 1:  # Process LHS (dataset A)
        # Emit the LHS row only if it doesn&#x27;t match the last RHS row
        if last_rhs != row:
            emit(row)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Cartesian Product (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span><span>﻿</span></span>) </summary><div class="indented"><p id="1432e7d3-01e5-8047-8a46-dbb83758fc9a" class="">Combines every row of one dataset with every row of another dataset</p><p id="0d78c376-0f4a-4b66-8725-e810a18690bc" class=""><strong>In SQL: </strong></p><p id="13f7451d-b7a7-4449-87f0-3aad85741597" class="">SELECT …, … FROM T1, T2</p><p id="0909ab73-d11c-42c6-b4ad-61fb62c605b0" class="">SQL calls this a type of join — “<code>cross join</code>”</p><p id="1432e7d3-01e5-802f-bfde-dafb953b793e" class="">Expensive as it results in <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M\times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span><span>﻿</span></span> rows. </p><figure id="bdf351c8-3975-46ab-ba51-f64f85cf7ddf" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_13.13.35.png"><img style="width:336px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_13.13.35.png"/></a></figure><p id="ab79d8b1-79f4-4521-81ad-77a2f656a654" class=""><strong>In MapReduce: </strong></p><p id="1432e7d3-01e5-802d-ae7f-c49bab1a7da1" class="">Requires careful handling to avoid massive computational overhead. Instead of distributing all rows across all nodes, use <strong>custom readers</strong> to manage pairing rows from one file with rows from another.</p><ul id="1432e7d3-01e5-80d8-aa98-e5e55d2325c9" class="bulleted-list"><li style="list-style-type:disc"><strong>Custom Reader Class</strong><ul id="1432e7d3-01e5-803a-8da4-df0f717c0b01" class="bulleted-list"><li style="list-style-type:circle">The job setup assigns blocks (splits) of the two datasets to the reader<ul id="1432e7d3-01e5-8099-82e8-c65fb6eee358" class="toggle"><li><details open=""><summary>e.g. </summary><ul id="1432e7d3-01e5-80c8-b6da-c0838bc62e7c" class="bulleted-list"><li style="list-style-type:disc">File1 = HDFS blocks [1], [2], [3]</li></ul><ul id="1432e7d3-01e5-80ec-a612-cb4944670530" class="bulleted-list"><li style="list-style-type:disc">File2 = HDFS blocks [a], [b], [c]</li></ul><ul id="1432e7d3-01e5-80b2-8523-faaa747828d2" class="bulleted-list"><li style="list-style-type:disc">Cross = [1a] [1b] [1c] [2a] [2b] [2c] [3a] [3b] [3c]</li></ul></details></li></ul></li></ul><ul id="1432e7d3-01e5-80b5-9066-f4ade0fe966a" class="bulleted-list"><li style="list-style-type:circle">The reader iterates through all records in one block (e.g., <code>[3]</code> from File1) and pairs each with all records in another block (e.g., <code>[a]</code> from File2).</li></ul><ul id="1432e7d3-01e5-8030-9454-cf30db3121e5" class="bulleted-list"><li style="list-style-type:circle">This ensures that the cross-product is computed locally for specific subsets of the data.</li></ul></li></ul><ul id="1432e7d3-01e5-808e-b050-fa3a72d7bbcb" class="bulleted-list"><li style="list-style-type:disc">Mapper (identity function; does nothing) <ul id="1432e7d3-01e5-8086-9c25-c040a20b7b1b" class="bulleted-list"><li style="list-style-type:circle">Simply emitting the rows produced by the custom reader. This allows the results of the Cartesian Product to be passed downstream, where they can be filtered (e.g., using a <code>SELECT</code> operation to limit tuples).</li></ul></li></ul><ul id="1432e7d3-01e5-800f-9e64-c0a5dceaa2ff" class="bulleted-list"><li style="list-style-type:disc">Reducer <ul id="1432e7d3-01e5-80d2-bd16-c6c2697aba06" class="bulleted-list"><li style="list-style-type:circle">Not required for a Cartesian Product. </li></ul><ul id="1432e7d3-01e5-80b0-b134-cc8b7c93b853" class="bulleted-list"><li style="list-style-type:circle">However, filtering operations can be pipelined in the reducer stage to process results.</li></ul></li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-805c-89a4-f5ae5401c4bc" class="code"><code class="language-Python">class CrossReader:
    def __init__(self, file1_split, file2_split):
        self.file1 = open(file1_split, &#x27;r&#x27;)
        self.file2 = open(file2_split, &#x27;r&#x27;)
        self.file2_records = self.file2.readlines()  # Cache file2 records in memory

    def read(self):
        for record1 in self.file1:
            for record2 in self.file2_records:
                yield (record1.strip(), record2.strip())  # Pair each record from file1 with all records in file2</code></pre><p id="1432e7d3-01e5-8066-8c9f-fb57f2977c57" class=""><strong>Performance</strong></p><ul id="1432e7d3-01e5-80be-a20c-d37d3d001717" class="bulleted-list"><li style="list-style-type:disc">The Cartesian Product grows quadratically in size (<link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">N\times M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span><span>﻿</span></span>)</li></ul><p id="1432e7d3-01e5-80f9-bf28-f9bec204f98a" class=""><strong>Notes </strong></p><ul id="1432e7d3-01e5-8077-9a2a-f41ce6a676d2" class="bulleted-list"><li style="list-style-type:disc">Memory Considerations: Caching all records from File2 in memory (as shown in the reader) works only for smaller datasets. For larger datasets, a more distributed solution would involve partitioning File2 records across nodes and streaming data dynamically.</li></ul><ul id="1432e7d3-01e5-8016-8cd6-c5fab83afe74" class="bulleted-list"><li style="list-style-type:disc">Filtering: Ideally, the Cartesian Product is followed by filtering (e.g., using <code>SELECT ... WHERE ...</code>) to reduce the # of resulting rows.</li></ul><ul id="1432e7d3-01e5-80a0-b627-e9e3a04d20c9" class="bulleted-list"><li style="list-style-type:disc">Avoidance: Whenever possible, replace a Cartesian Product with more targeted operations (e.g., joins with filtering conditions).</li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Aggregation</summary><div class="indented"><p id="1432e7d3-01e5-8097-888d-d23bf0066951" class="">The Reduce in MapReduce is often called the “Aggregation Phase” </p><p id="1432e7d3-01e5-80d1-9b17-f77b51de2a7b" class="">Every SQL aggregation function is done on the <code>reduce</code> side. </p><p id="1432e7d3-01e5-803c-a758-ee5489332481" class="">SQL Aggregate Types: COUNT, SUM, MIN, MAX, AVG</p></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3;margin:0">Inner Join </summary><div class="indented"><p id="6f6ce75c-988e-4841-af20-9df89a692de3" class=""><strong>In SQL:</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-8092-91f3-c47937e7b2ef" class="code"><code class="language-SQL">SELECT *
FROM table1
INNER JOIN table2
ON table1.key = table2.key;</code></pre><p id="ce7d4394-d800-461f-b868-362aa498f541" class=""><strong>Types of Relationships: </strong></p><p id="24d5d819-8805-4ab6-ad49-3963965e2647" class="">Efficiency of a join depends on the type of relationship: </p><figure id="aa5971e5-5a9b-49f6-801d-2eb03e7663b7" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_14.01.49.png"><img style="width:336px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_14.01.49.png"/></a></figure><ol type="1" id="5f539480-8ab2-4081-b077-664a293aae03" class="numbered-list" start="1"><li><strong>One-to-One Joins (easy)</strong></li></ol><ul id="1492e7d3-01e5-8009-abaa-ee721e045f66" class="bulleted-list"><li style="list-style-type:disc">1 → ? </li></ul><ul id="1432e7d3-01e5-80e4-8bf4-fae4bc01a78f" class="bulleted-list"><li style="list-style-type:disc">(Like merge sort) —match one row from each table using the join key.</li></ul><ol type="1" id="276495ae-9739-41a5-9879-86f6bd279b5d" class="numbered-list" start="2"><li><strong>One-to-many (medium)</strong></li></ol><ul id="1492e7d3-01e5-806b-a7e6-e195b435fcd9" class="bulleted-list"><li style="list-style-type:disc">1 → 0+</li></ul><ul id="5227aa5b-267e-4446-a7fc-c52dfc1a9e13" class="bulleted-list"><li style="list-style-type:disc">One pass, low memory usage</li></ul><ul id="1432e7d3-01e5-8010-ae75-c0919852eed1" class="bulleted-list"><li style="list-style-type:disc">Hold ONE tuple from the &quot;one&quot; side in memory. Then iterate over matching (by join key) tuples from the &quot;many&quot; side.</li></ul><ol type="1" id="a84e6369-db1a-45cb-a96e-66a018b32cad" class="numbered-list" start="3"><li><strong>Many-to-many (hard) </strong></li></ol><ul id="1492e7d3-01e5-8081-b2b0-ee5d57c055ac" class="bulleted-list"><li style="list-style-type:disc">? → ?</li></ul><ul id="1432e7d3-01e5-80c3-be84-dd242ce25785" class="bulleted-list"><li style="list-style-type:disc">Requires holding all tuples with the same key from both tables in memory, then performing a Cartesian cross for matches.</li></ul><hr id="0fa402de-ec14-404f-b6cd-535ab10d08fd"/><h2 id="37cbe8c0-d1ca-4cd1-b511-3bddd12e194e" class="">In MapReduce </h2><p id="8cb32816-a081-496d-9168-7bde44ca0bc5" class="">3 options, ranked by efficiency: </p><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Hash Join</strong></summary><div class="indented"><p id="1432e7d3-01e5-807b-a502-c8a6ac335b46" class=""><strong>When to Use</strong><div class="indented"><p id="1432e7d3-01e5-80d0-a8ff-dcad163a3434" class="">One table is SMALL ENOUGH to fit in memory</p></div></p><p id="1432e7d3-01e5-801d-a181-fdbe85d48931" class=""><strong>How it works</strong></p><ul id="1432e7d3-01e5-8022-8372-e725ed6b3a69" class="bulleted-list"><li style="list-style-type:disc">Setup (in a Mapper | Reducer): <ul id="1442e7d3-01e5-8020-9302-c23aae9fd683" class="bulleted-list"><li style="list-style-type:circle">Load the smaller dataset into memory as a hash table.</li></ul></li></ul><ul id="1442e7d3-01e5-80e1-9def-d76505caf570" class="bulleted-list"><li style="list-style-type:disc">Map: <ul id="1432e7d3-01e5-80e5-a4c6-f2c5669cf289" class="bulleted-list"><li style="list-style-type:circle">Each mapper processes its split of the larger dataset, joining rows with the in-memory hash table.</li></ul></li></ul><p id="1432e7d3-01e5-8008-b306-f2a0063067ef" class=""><strong>Benefits</strong><div class="indented"><ul id="1432e7d3-01e5-8038-a016-e3e4dc323675" class="bulleted-list"><li style="list-style-type:disc">Map-side only, avoids shuffle ⇒ fast</li></ul><ul id="1442e7d3-01e5-80ac-916b-f4a29e195519" class="bulleted-list"><li style="list-style-type:disc">However, if the big table is shuffled by key anyways, not much savings. </li></ul></div></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1432e7d3-01e5-8031-8cf7-db04e9a3b18b" class="code"><code class="language-Python">class Mapper:

	def setup():
		# load the dataset and put it in a hash table
		hash_table = ...

	def map(_, record):
	    join_key = extract_key(record)
	    if join_key in hash_table:
			    # For each record in the larger dataset, Check for a match in the hash table.
	        for matching_record in hash_table[join_key]:
	            emit(joined_record(record, matching_record))</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Map-Side Join</strong> </summary><div class="indented"><p id="1432e7d3-01e5-80ac-954f-c3ab398de349" class="">Similar to the map-side cross</p><p id="1432e7d3-01e5-802d-a540-c241a6107de3" class=""><strong>When to Use</strong><div class="indented"><p id="1432e7d3-01e5-80e1-8ee0-ea805ba64849" class="">Both input files are:</p><ul id="1482e7d3-01e5-800d-b546-f603ad75f339" class="bulleted-list"><li style="list-style-type:disc"><strong>large </strong>(⇒ can’t use Hash-Join)</li></ul><ul id="1482e7d3-01e5-80ba-880d-e9ca2044b28e" class="bulleted-list"><li style="list-style-type:disc"><strong>co-partitioned: </strong><ul id="1442e7d3-01e5-806b-9662-f6d931b174b4" class="bulleted-list"><li style="list-style-type:circle">ALREADY sorted and partitioned by the SAME join key, AND</li></ul><ul id="1442e7d3-01e5-807d-8035-cbcb10be65f3" class="bulleted-list"><li style="list-style-type:circle">Into the exact SAME # of partitions</li></ul><p id="1482e7d3-01e5-80a8-bb6c-ce4c33237c89" class="">⇒ Hence, it does not apply to: <code>SELECT * FROM A join B ON ...</code> ; our input files are not sorted and partitioned by key. But, if this joining 2 <strong>subqueries together</strong>; for example you might be doing aggregation (e.g. group by) on both tables, and then you want to join them. So long as they will be <strong>co-partitioned</strong> so long as you make sure to use the same # reducers for both group-by’s. </p></li></ul></div></p><p id="1432e7d3-01e5-80c5-82e6-db43956811cc" class=""><strong>How it works</strong></p><ul id="1442e7d3-01e5-8043-ad92-f3ada7d94265" class="bulleted-list"><li style="list-style-type:disc"><code>MultipleInputFiles</code> class</li></ul><ul id="1442e7d3-01e5-80fa-a11b-e7fec6b7247d" class="bulleted-list"><li style="list-style-type:disc">Like a dot-product (instead of a cross product)</li></ul><ul id="1442e7d3-01e5-8043-8f87-e620d15348f9" class="bulleted-list"><li style="list-style-type:disc">One worker gets the 1st partition of both files, the other gets the 2nd partition of both files, and so on. Since the partitions are in sorted order, rows from the two datasets are matched directly ⇒ we’re basically doing <strong>merge sort</strong>; look at smallest by key, join if equal, skip (for <strong>inner</strong> join) or null (for <strong>outer</strong> join).</li></ul><p id="1432e7d3-01e5-8090-87ec-df2bd2ee843d" class=""><strong>Benefits:</strong><div class="indented"><p id="1432e7d3-01e5-8081-a9e2-cc1b569eac78" class="">The join happens at the map phase (without a shuffle) ⇒ fast</p></div></p><p id="1442e7d3-01e5-8029-b0f0-c0f0c862dbe3" class=""><strong>Note: </strong><div class="indented"><p id="1442e7d3-01e5-80df-86f7-c19ce640cb28" class="">Although we call it “map-side” join, it does not have to be done in a Mapper. It should really be called “in-place” join. It just means that we don’t need a shuffle. </p></div></p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Reduce-Side Join </strong></summary><div class="indented"><p id="1432e7d3-01e5-80a8-8258-e15a5142b626" class=""><strong>USE IF:</strong> <div class="indented"><p id="1432e7d3-01e5-8069-ab74-f006cee4447d" class="">(Always possible) Use only if other approaches aren’t feasible </p></div></p><p id="1432e7d3-01e5-8011-9c15-fda7bc364742" class=""><strong>How it works:</strong></p><ul id="1432e7d3-01e5-8085-b0b6-fb9fc9fe4b17" class="bulleted-list"><li style="list-style-type:disc"><code>MultipleInputFiles</code> class</li></ul><ul id="1432e7d3-01e5-8064-b463-f09921e0e2fb" class="bulleted-list"><li style="list-style-type:disc">Mappers ⇒ (join key, row)</li></ul><ul id="1432e7d3-01e5-80bf-9661-f2415398061f" class="bulleted-list"><li style="list-style-type:disc">Reducers: group rows by the join key, then join them.</li></ul><p id="1432e7d3-01e5-804e-9c1c-f6559cec9419" class=""><strong>Steps for Specific Relationships:</strong><div class="indented"><ol type="a" id="1432e7d3-01e5-8078-b241-f31078d064b4" class="numbered-list" start="1"><li><strong>One-to-One Join:</strong><ul id="1432e7d3-01e5-8078-b94d-c0d4041c4adb" class="bulleted-list"><li style="list-style-type:disc">Straightforward since only one tuple exists per key for each dataset.</li></ul><ul id="1432e7d3-01e5-80b1-92b9-e195a2f1c411" class="bulleted-list"><li style="list-style-type:disc">Sort order does not matter.</li></ul></li></ol><ol type="a" id="1432e7d3-01e5-80ed-a45f-d625b194d116" class="numbered-list" start="2"><li><strong>One-to-Many Join:</strong><ul id="1432e7d3-01e5-80ba-bb4b-d74a30e6640b" class="bulleted-list"><li style="list-style-type:disc">Reducers hold the &quot;one&quot; tuple in memory and join it with all &quot;many&quot; tuples.</li></ul><ul id="1432e7d3-01e5-8094-a6e1-d68a7bdd3b23" class="bulleted-list"><li style="list-style-type:disc">Use <strong>Secondary Sorting Pattern</strong> to ensure the &quot;one&quot; tuple arrives first.</li></ul></li></ol><ol type="a" id="1432e7d3-01e5-8035-9d1f-f4b67952c31a" class="numbered-list" start="3"><li><strong>Many-to-Many Join:</strong><ul id="1432e7d3-01e5-80b8-92df-f7e4992c28a7" class="bulleted-list"><li style="list-style-type:disc">Requires holding all tuples for a key from both datasets in memory, then performing a Cartesian cross.</li></ul></li></ol></div></p></div></details><h3 id="1432e7d3-01e5-80e1-a2a3-c1aeb8168f77" class=""><strong>Summary</strong></h3><table id="1442e7d3-01e5-8060-a807-f874720f0922" class="simple-table"><thead class="simple-table-header"><tr id="1442e7d3-01e5-8003-9f6b-c167075c6590"><th id="VleP" class="simple-table-header-color simple-table-header"><strong>Method</strong></th><th id="&gt;}Jk" class="simple-table-header-color simple-table-header"><strong>Best For</strong></th><th id="VcbF" class="simple-table-header-color simple-table-header"><strong>Advantages</strong></th><th id="\odX" class="simple-table-header-color simple-table-header"><strong>Disadvantages</strong></th></tr></thead><tbody><tr id="1442e7d3-01e5-806c-9696-ff28f302709c"><th id="VleP" class="simple-table-header-color simple-table-header">Hash Join</th><td id="&gt;}Jk" class="">Small datasets in memory</td><td id="VcbF" class="">Fast, avoids shuffle</td><td id="\odX" class="">Limited by memory</td></tr><tr id="1442e7d3-01e5-802c-9ce9-d8d7f09faf84"><th id="VleP" class="simple-table-header-color simple-table-header">Map-Side Join</th><td id="&gt;}Jk" class="">Pre-sorted, partitioned data</td><td id="VcbF" class="">Fast, avoids reduce phase</td><td id="\odX" class="">Requires preprocessing</td></tr><tr id="1442e7d3-01e5-80c4-b9b6-d5b7cf31c841"><th id="VleP" class="simple-table-header-color simple-table-header">Reduce-Side Join</th><td id="&gt;}Jk" class="">Large datasets, many-to-many</td><td id="VcbF" class="">General-purpose, always works</td><td id="\odX" class="">Slow, requires shuffle and high memory</td></tr></tbody></table><p id="1442e7d3-01e5-8094-a052-d9ded13007cc" class=""><strong>Optimization Notes</strong></p><ul id="1442e7d3-01e5-808a-9de4-c5c19f1adbc8" class="bulleted-list"><li style="list-style-type:disc">Avoid Many→Many Joins: Extremely expensive; explore alternate query plans if possible.</li></ul><ul id="1482e7d3-01e5-8009-88aa-edca2bd49121" class="bulleted-list"><li style="list-style-type:disc"><strong>(aside) Tertiary Sorting:  </strong>If your query is like: SELECT a.key, a.thing, b.other from a JOIN b ON key ORDER BY a.key, a.thing, then you can get the <strong>sort/order-by </strong>for free. If you’re doing a reduce-side join anyway…might as well have the keys by (a.key, origin, a.thing_or_nothing). Now the values arrive sorted by the sort column, too!</li></ul><ul id="1442e7d3-01e5-80b4-abc6-cee6d467eb42" class="bulleted-list"><li style="list-style-type:disc">Partitioner: Ensure rows with the same join key are sent to the same reducer.</li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Outer Join </summary><div class="indented"><p id="1432e7d3-01e5-80f4-9976-fe11e2426c8c" class="">Same logic as <code>inner-join</code>, except you now have to handle the empty case instead of skipping the unpaired tuple.</p></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3;margin:0">Putting it Together</summary><div class="indented"><p id="1442e7d3-01e5-8027-9ee9-dc105e1ee26c" class=""><em><mark class="highlight-gray">Generic SQL-on-Hadoop implementation (close to what Hive does)</mark></em></p><p id="1472e7d3-01e5-804c-8435-c22d9e21cf1a" class="">Steps: </p><ol type="1" id="1442e7d3-01e5-803d-8f27-d59d76df530b" class="numbered-list" start="1"><li>Build logical plan<ul id="1472e7d3-01e5-808d-9adf-f619928db4ad" class="bulleted-list"><li style="list-style-type:disc">We build out the concrete syntax tree: </li></ul></li></ol><ol type="1" id="1442e7d3-01e5-805f-8661-c84893eea022" class="numbered-list" start="2"><li>Optimize plan for map-reduce<ul id="1472e7d3-01e5-80a0-a5e6-dd2e2ac0a598" class="bulleted-list"><li style="list-style-type:disc">Reduce memory-use / improve speed. </li></ul><ul id="1472e7d3-01e5-803a-941c-d2272da1423f" class="bulleted-list"><li style="list-style-type:disc">Key: fewer tuples to join</li></ul></li></ol><ol type="1" id="1442e7d3-01e5-80d9-87c3-dff5552834a1" class="numbered-list" start="3"><li>Select physical plan</li></ol><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><mark class="highlight-purple"><strong>Example</strong></mark></summary><div class="indented"><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1442e7d3-01e5-8090-b489-f446ef2576d7" class="code"><code class="language-SQL">SELECT big1.fx, big2.fy, small.fz
FROM big1
JOIN big2 ON big1.id1 = big2.id1
JOIN small ON big1.id2 = small.id2
WHERE
	big1.fx = 2015 AND
	big2.f1 &lt; 40   AND
	big2.f2 &gt; 2;</code></pre><p id="1442e7d3-01e5-80f1-be81-cb52a140073a" class=""><strong>1. Build Logical Plan </strong></p><figure id="1442e7d3-01e5-8004-a42f-d6f815d5048e" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.03.35.png"><img style="width:192px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.03.35.png"/></a></figure><p id="1442e7d3-01e5-8086-b0b6-ce5f56f15f33" class=""><mark class="highlight-default"><code>big1</code></mark><mark class="highlight-default"> and </mark><mark class="highlight-default"><code>big2</code></mark><mark class="highlight-default"> are joined, and then  joined with small, then filtered (select operator) based on </mark><mark class="highlight-default"><code>big1.fx</code></mark><mark class="highlight-default">, </mark><mark class="highlight-default"><code>big2.f1</code></mark><mark class="highlight-default">, </mark><mark class="highlight-default"><code>big2.f2</code></mark><mark class="highlight-default">, and finally, projected (limit to </mark><mark class="highlight-default"><code>fx</code></mark><mark class="highlight-default">, </mark><mark class="highlight-default"><code>fy</code></mark><mark class="highlight-default">, </mark><mark class="highlight-default"><code>fz</code></mark><mark class="highlight-default">). </mark></p><p id="1442e7d3-01e5-8052-967a-e471ab6ccc79" class=""><strong>2. Optimize logical plan</strong></p><figure id="1442e7d3-01e5-8088-be00-c73bdee2ebdb" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.05.11.png"><img style="width:192px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.05.11.png"/></a></figure><ol type="1" id="1442e7d3-01e5-8047-96fd-ee265abe668b" class="numbered-list" start="1"><li><code>Big1</code> should be projected down to: <ul id="1442e7d3-01e5-8050-b468-d9c21ece4935" class="bulleted-list"><li style="list-style-type:disc"><code>fx</code>: because its needed for the final projection</li></ul><ul id="1442e7d3-01e5-8095-aa24-df507c0d4ee4" class="bulleted-list"><li style="list-style-type:disc"><code>id1</code>, <code>id2</code>: for the joins </li></ul></li></ol><ol type="1" id="1442e7d3-01e5-80d8-884f-f61df56e924d" class="numbered-list" start="2"><li><code>Big2</code> should be projected down to: <ul id="1442e7d3-01e5-8059-bb19-d8107fc85e1f" class="bulleted-list"><li style="list-style-type:disc"><code>fy</code>: because it’s needed for the final projection</li></ul><ul id="1442e7d3-01e5-8074-a0a3-c0c0c38ab133" class="bulleted-list"><li style="list-style-type:disc"><code>id1</code>: for the join</li></ul><ul id="1442e7d3-01e5-80f5-aee0-ebdb9de41dfc" class="bulleted-list"><li style="list-style-type:disc"><code>f1</code>, <code>f2</code>: for the “WHERE” selection</li></ul></li></ol><ol type="1" id="1442e7d3-01e5-80fc-8026-dddeeb26dc29" class="numbered-list" start="3"><li><code>Big1</code> and <code>Big2</code> should then be filtered by the “WHERE” clauses<p id="1442e7d3-01e5-80f5-96b1-f25d936f1314" class="">⇒ We no longer need a post-join filter as none of the “WHERE” clauses involve comparisons that are only valid on the joined tables.  </p></li></ol><p id="1442e7d3-01e5-808c-9e1e-c9446326b616" class=""><strong>Notes: </strong></p><ul id="1442e7d3-01e5-80e4-9524-d0d2866060c2" class="bulleted-list"><li style="list-style-type:disc">Filters that are between tables can only happen post-join. Filters that only apply to one table can be applied pre-join. </li></ul><ul id="1442e7d3-01e5-800b-aeb5-c3b23aaa717c" class="bulleted-list"><li style="list-style-type:disc">The final projection is still needed to remove the columns used as join keys and select criteria</li></ul><h3 id="1442e7d3-01e5-8020-b1f9-efc28a01de40" class=""><strong>3. Select Physical Plan</strong></h3><p id="1442e7d3-01e5-80c9-ba50-f258449d8a52" class="">The only choice to make is what type of <strong>join </strong>(recall: 3 types)</p><p id="1442e7d3-01e5-80e4-b5e5-dd949a174d29" class=""><code>small</code> is a small table ⇒ so a <em>Hash Join</em> is suitable.</p><p id="1442e7d3-01e5-80b0-93e0-c3ff6ed9308b" class=""><code>big1</code>, <code>big2</code> are both <strong>large</strong> &amp; <strong>not co-partitioned</strong> ⇒<em> Reduce-Side Join </em></p><figure id="1442e7d3-01e5-805b-9bfe-edb93dfb9d5a" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.09.27.png"><img style="width:192px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-19_at_19.09.27.png"/></a></figure><p id="1442e7d3-01e5-80d9-84cf-c263eadb970f" class="">Result: </p><figure id="1442e7d3-01e5-801b-8e5e-d2dd1162ef8c" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.31.24.png"><img style="width:192px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.31.24.png"/></a></figure><ul id="1442e7d3-01e5-809a-a3bd-df641982d9ee" class="bulleted-list"><li style="list-style-type:disc"><strong>scan</strong> = select + project (pipelined together)</li></ul><ul id="1442e7d3-01e5-80a4-aa13-ed4a6cd7b28b" class="bulleted-list"><li style="list-style-type:disc"><strong>sink </strong>= projection + write the output (pipelined together)</li></ul><ul id="1442e7d3-01e5-805b-b232-e0f67390ac6d" class="bulleted-list"><li style="list-style-type:disc"><strong>shuffle J: </strong>shuffles by the join-key (reduce-side join)</li></ul><figure id="1442e7d3-01e5-80c0-b41d-f232308adb6f" class="image" style="text-align:center"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.37.44.png"><img style="width:240px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.37.44.png"/></a></figure><ul id="1442e7d3-01e5-804c-a95f-cf66cdca3c8f" class="bulleted-list"><li style="list-style-type:disc">Note: for other examples, whatever WHERE clauses are between tables, need to occur on the reduce side of the join. </li></ul><ul id="1442e7d3-01e5-80ab-9bb6-fa39a454d1ef" class="bulleted-list"><li style="list-style-type:disc">Note: the hash-table only needs to store ‘id2’ column. </li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1442e7d3-01e5-8085-b85e-c396d072a739" class="code"><code class="language-Python"># Assume a 1-&gt;many relationship (so order matters), emit 1/2 with key so that the 1 side comes before the 2 side

# Scan of Big 1
def map(id, row):
		if row[&#x27;fx&#x27;] == 2015:
				# since we&#x27;re piping it directly into a shuffle:
				emit ( (row[&#x27;id1&#x27;], 1), row[&#x27;id2&#x27;,&#x27;fx&#x27;] )

# Scan of Big 2
def map(id, row):
		if row[&#x27;f1&#x27;] &lt; 40 and row[&#x27;f2&#x27;] &gt; 2:
			emit ( (row[&#x27;id1&#x27;],2) (row[&#x27;fy&#x27;]) )

# Hash Join (can be done as reduce or map)
def reduce(id, row):
		if id[1] == 1:
				# row from side #1
				rememberedRow = (id[0], row)
		elif id[0] == rememberedRow[0]:
				# row from side #2 and matches row we&#x27;re remembering
				if row[&#x27;id2&#x27;] in hashTable:
						join rememberedRow, row hashTable[...]

		# then do the projection (sink part)
		... </code></pre><p id="1442e7d3-01e5-8010-919a-ea2e05b9fa3e" class="">
</p></div></details></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Storing the Schema </strong></summary><div class="indented"><p id="1442e7d3-01e5-805f-aad3-f472020728f8" class="">How does it know which file is being referred to when we say ‘big1’ ? </p><ul id="1442e7d3-01e5-80a5-a3f0-e508fdd372b6" class="bulleted-list"><li style="list-style-type:disc">HDFS stores the file and its schema (as metadata file) </li></ul><ul id="1442e7d3-01e5-8088-9ad0-dfd6042f791c" class="bulleted-list"><li style="list-style-type:disc">File could be stored in multiple partitions (from previous MR job) </li></ul><ul id="1442e7d3-01e5-8010-a4f0-f3f7b8c94205" class="bulleted-list"><li style="list-style-type:disc">So it knows what you mean when you say ‘id1’, ‘fx’, etc. </li></ul></div></details><hr id="1442e7d3-01e5-806e-91a8-f95dd0291471"/><h2 id="1442e7d3-01e5-809a-ba4b-e915c3bea07b" class="">In Spark </h2><ul id="1442e7d3-01e5-80f1-876a-fd0a1f4a6c3e" class="bulleted-list"><li style="list-style-type:disc">Spark does the <em>planning</em> already, and writing Spark is pretty close to writing imperative queries:</li></ul><ul id="1442e7d3-01e5-801c-b6d1-edbd26eaa163" class="bulleted-list"><li style="list-style-type:disc">Most Relational operators are ALREADY RDD transformations: <ul id="1442e7d3-01e5-8053-9f57-e4c9857f9be4" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Select / Project: (Base RDD or </mark><mark class="highlight-default"><code>.filter</code></mark><mark class="highlight-default">) / </mark><mark class="highlight-default"><code>.map </code></mark></li></ul><ul id="1442e7d3-01e5-80c7-962c-d22a55415369" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Join : </mark><mark class="highlight-default"><code>.join </code></mark></li></ul><ul id="1442e7d3-01e5-8053-91ae-e2f2120d383e" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Union : </mark><mark class="highlight-default"><code>.union </code></mark></li></ul><ul id="1442e7d3-01e5-8014-90e8-d40ae4642a47" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Cartesian Product: </mark><mark class="highlight-default"><code>.cartesian</code></mark><mark class="highlight-default"> </mark></li></ul><ul id="1442e7d3-01e5-8035-9b73-ced94654d330" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Count: </mark><mark class="highlight-default"><code>.count</code></mark><mark class="highlight-default"> </mark></li></ul><ul id="1442e7d3-01e5-8044-8e20-edad8b0d5d4a" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-default">Sum: </mark><mark class="highlight-default"><code>.sum</code></mark><mark class="highlight-default"> , </mark><mark class="highlight-default"><code>.reduce(</code></mark><em><mark class="highlight-default"><code>+</code></mark></em><mark class="highlight-default"><code>)</code></mark></li></ul></li></ul><h3 id="1442e7d3-01e5-8074-ab34-fd1698cf8af6" class=""><mark class="highlight-default"><code><strong>.Join()</strong></code></mark></h3><figure id="1442e7d3-01e5-8061-9cb7-c89753e28c25" class="image"><a href="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.57.38.png"><img style="width:192px" src="07%20%E2%80%94%20Relational%20Data/Screenshot_2024-11-20_at_15.57.38.png"/></a></figure><ul id="1442e7d3-01e5-809d-a86f-d6b748624b22" class="bulleted-list"><li style="list-style-type:disc">Will do map-side or reduce-side automatically, depending on whether it’s a narrow or a wide dependency.</li></ul><ul id="1442e7d3-01e5-80db-97b5-f8f25aa8460f" class="bulleted-list"><li style="list-style-type:disc">If you want a hash join, use a broadcast variable (i.e. what you did in A2)</li></ul><h3 id="1442e7d3-01e5-8003-9c71-ed10cbc13a87" class="">DataFrames</h3><p id="1442e7d3-01e5-804a-83fe-d2a24207989a" class="">Skipped this section (slides:  96→104). </p><ul id="1442e7d3-01e5-800a-b82b-f9b11b22c9c7" class="bulleted-list"><li style="list-style-type:disc">Because won’t be usable on A6 (besides to do checking). </li></ul><ul id="1442e7d3-01e5-8052-8b49-fc690b83ae75" class="bulleted-list"><li style="list-style-type:disc">Q: need to know for Final? </li></ul><hr id="1442e7d3-01e5-808c-a777-cbad57abe927"/><h2 id="1442e7d3-01e5-8085-89e5-ce142c1f923e" class="">Hadoop vs. Database </h2><p id="1442e7d3-01e5-8070-9c59-f3ed73f0347f" class="">MapReduce:</p><ul id="1442e7d3-01e5-8026-b55a-e19ad031b1bf" class="bulleted-list"><li style="list-style-type:disc">All it has is a brute force table scans. </li></ul><ul id="1442e7d3-01e5-8040-9f7b-ce94f577d378" class="bulleted-list"><li style="list-style-type:disc">Read only: can’t insert/update. </li></ul><ul id="1442e7d3-01e5-80e8-890c-cdd9adf6099e" class="bulleted-list"><li style="list-style-type:disc">Can’t run SQL queries on it (w’out Hive)</li></ul><p id="1442e7d3-01e5-8071-ba14-c59056fe56c0" class="">MR is a bad implementation of a database because it doesn’t have <strong>indexing</strong>, relations, etc.</p><ul id="1442e7d3-01e5-8045-99d0-d7002ac7e8b5" class="bulleted-list"><li style="list-style-type:disc">An index speeds things up because it already has columns sorted by index, so doing things like a <em>Selection</em> clause is ultrafast. In MR, you would have to search the whole table. Same goes with join using an index vs. brute force. </li></ul><ul id="1442e7d3-01e5-80a2-8da2-fe174d607560" class="bulleted-list"><li style="list-style-type:disc">It also has to do <strong>text parsing</strong> of files which is slower than having an indexed file. Loading lines, splitting on whitespace, parsing integers are all <strong>very slow</strong> operations.</li></ul><p id="1442e7d3-01e5-80c3-a498-c84e02c6d3f9" class="">So why use it? </p><ul id="1442e7d3-01e5-8015-ae60-d7891883d469" class="bulleted-list"><li style="list-style-type:disc"> Designed for Big Data and Clustering</li></ul><h3 id="1442e7d3-01e5-80e6-a910-fe5ef74bc06e" class="">Vertica </h3><p id="1442e7d3-01e5-8097-9ec4-cc3b26ce1409" class="">Skipped Section (slides 106→110) </p><h3 id="1442e7d3-01e5-80bd-adfc-f1f1e8d9b792" class="">Sequence (Row) File </h3><p id="1442e7d3-01e5-8009-bc8c-c94d47e83083" class="">Instead of storing tuples in a text files, what if we use a <strong>binary format</strong>? </p><ul id="1442e7d3-01e5-8030-9338-e080903f4535" class="bulleted-list"><li style="list-style-type:disc">A schema separates <strong>logical</strong> and <strong>physical</strong> views <ul id="1442e7d3-01e5-809a-b65b-d712fa1024d5" class="bulleted-list"><li style="list-style-type:circle">logical: the text file view</li></ul><ul id="1442e7d3-01e5-80af-a929-dade503c3d9f" class="bulleted-list"><li style="list-style-type:circle">physical: how bytes are actually stored</li></ul></li></ul><p id="1442e7d3-01e5-8077-8cee-e8485e8b68ab" class=""><strong>2 Options: </strong></p><ol type="1" id="1442e7d3-01e5-80f9-aa28-df4516ac32c8" class="numbered-list" start="1"><li><strong>Row Store</strong><p id="1442e7d3-01e5-8064-8798-e2a85b1d1455" class="">We store the byte encoding of each row (sequence of bytes). </p><p id="1442e7d3-01e5-806e-b0d5-c4861c0fdc99" class="">Pro: </p><ul id="1442e7d3-01e5-8097-b974-dea398a513fd" class="bulleted-list"><li style="list-style-type:disc">Easier to modify a record: in-place updates </li></ul><p id="1442e7d3-01e5-803c-8558-e5fa52eb1d95" class="">Cons: </p><ul id="1442e7d3-01e5-80af-9668-d20306e52fc4" class="bulleted-list"><li style="list-style-type:disc">Reading unnecessary data when processing</li></ul><ul id="1442e7d3-01e5-8098-b025-c4c8356450ba" class="bulleted-list"><li style="list-style-type:disc">Need to load rows, and drop whatever isn’t necessary. </li></ul></li></ol><ol type="1" id="1442e7d3-01e5-8043-9a7d-e947a9780316" class="numbered-list" start="2"><li><strong>Column Store</strong><p id="1442e7d3-01e5-80dc-a036-cb09429cfff7" class="">Pros: </p><ul id="1442e7d3-01e5-8030-b2d6-e8b2fd1fd956" class="bulleted-list"><li style="list-style-type:disc">Only read necessary data when processing</li></ul><ul id="1442e7d3-01e5-80c2-9649-c07310f79c40" class="bulleted-list"><li style="list-style-type:disc">Only need to load the necessary columns. </li></ul><ul id="1442e7d3-01e5-8033-8653-ee80d8a195c5" class="bulleted-list"><li style="list-style-type:disc">Better compression (Repetitive columns are grouped together). </li></ul><p id="1442e7d3-01e5-805e-8737-c576fac042b9" class="">Con: </p><ul id="1442e7d3-01e5-806a-8f37-cd53795b2724" class="bulleted-list"><li style="list-style-type:disc">Need a separate file for each column (else, insertion is too hard). Otherwise (all in one file), it will need to be read only. </li></ul></li></ol><hr id="1442e7d3-01e5-8049-918c-d373aba8a1a5"/><h3 id="1442e7d3-01e5-8084-9d55-eafa3bf3b9ce" class=""><strong>Parquet File</strong></h3><p id="1442e7d3-01e5-8015-8836-e6d735500f0c" class="">Hadoop can use a <strong>Parquet file, </strong>a column storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language. </p><p id="1442e7d3-01e5-8045-8bcd-ef54d719568f" class="">Thus, we get Best of both worlds: Hadoop + better compression &amp; read efficiency</p><p id="1442e7d3-01e5-809e-a035-d18e194e749a" class="">In Spark: </p><ul id="1442e7d3-01e5-805f-bc01-f4d736a8d0d0" class="bulleted-list"><li style="list-style-type:disc">spark.read.parquet(“path/to/parquet/file.parquet”) → DataFrame</li></ul><ul id="1442e7d3-01e5-80a6-ac2e-dd34c6172bab" class="bulleted-list"><li style="list-style-type:disc">DF.write.parquet(“path/to/output/file.parquet”)</li></ul><p id="1442e7d3-01e5-8048-aa9b-d205b261431b" class="">
</p><p id="1442e7d3-01e5-808f-9caa-c7875965d60b" class="">
</p><p id="1442e7d3-01e5-804a-b97e-c817f1fdf5de" class="">
</p><p id="1442e7d3-01e5-8007-bf6f-e6ecac57277f" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>