<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>06 —  ML Part 1 (Data Mining)</title><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/></head><body><article id="1292e7d3-01e5-8007-842d-fd6f7cfd975a" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/folder_purple.svg"/></div><h1 class="page-title">06 —  ML Part 1 (Data Mining)</h1><p class="page-description"></p></header><div class="page-body"><p id="13b2e7d3-01e5-80b7-9612-c710c96b2118" class="">These notes don’t cover slides 69-85; a high level overview of ML in practice. </p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13b2e7d3-01e5-807f-a9e6-fce24d99db0f"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="b66c4df0-070b-46b0-a6e5-34cd84bc1e97" class="">Spark itself is not meant for machine learning, but a large part of machine learning is cleaning the data to make it useful (<strong>data mining</strong>, text processing, formatting, etc.) This is where spark becomes useful </p></div></figure><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0"><mark class="highlight-red">Background</mark> </summary><div class="indented"><p id="1292e7d3-01e5-8033-9be4-ce85d77933c6" class=""><strong>Data Mining vs. info-retrieval</strong></p><div id="15c2e7d3-01e5-8038-9524-e61776d69a6c" class="column-list"><div id="dbfe8193-e77b-40d5-a5a5-546714dc7159" style="width:50%" class="column"><p id="15c2e7d3-01e5-809b-9868-cba760534656" class=""><strong>Info-retrieval:</strong></p><ul id="1292e7d3-01e5-8067-b33d-ed0102001c49" class="bulleted-list"><li style="list-style-type:disc">find docs that match retrieval</li></ul><ul id="15c2e7d3-01e5-80d5-9027-f69f18ab26ee" class="bulleted-list"><li style="list-style-type:disc">e.g. all docs with the keyword &quot;ice-cream&quot;</li></ul></div><div id="4dfb2733-82f1-48c7-99da-f00d8a836d31" style="width:50%" class="column"><p id="1292e7d3-01e5-803d-a23a-ea645d20908f" class=""><strong>Data mining: </strong></p><ul id="15c2e7d3-01e5-80b6-aabb-db1ed4b3241d" class="bulleted-list"><li style="list-style-type:disc">more abstract description of what your looking for (not a set of key words)</li></ul><ul id="15c2e7d3-01e5-8097-a092-f76a362ef428" class="bulleted-list"><li style="list-style-type:disc">e.g. all docs “<em><strong>about”</strong></em> ice-cream</li></ul></div></div><hr id="1292e7d3-01e5-8074-81d3-e498d799cce0"/><p id="1292e7d3-01e5-8062-890d-c9eac01fb872" class=""><strong>We’re Interested In </strong></p><ul id="15c2e7d3-01e5-802f-8256-f0d3dcb6b714" class="bulleted-list"><li style="list-style-type:disc">trainining classification models</li></ul><ul id="15c2e7d3-01e5-8006-9800-ee5003812eae" class="bulleted-list"><li style="list-style-type:disc"><em>using supervised learning</em>. </li></ul><p id="15c2e7d3-01e5-804d-96e2-c88b1b4ecd97" class=""><strong>Example — “Spam or Ham”</strong></p><ul id="13b2e7d3-01e5-80a3-9071-c8e93e865933" class="bulleted-list"><li style="list-style-type:disc">classifying emails as “spam” or “not-spam” (ham). </li></ul><hr id="1292e7d3-01e5-805f-b49b-fe9063409fcd"/><p id="1292e7d3-01e5-8021-bb10-ef79954ae999" class=""><strong>Features vs. Embeddings </strong></p><p id="1292e7d3-01e5-803a-bb47-d5b8c702b464" class="">Embedding of a complex object into a lower dimensional space </p><ul id="15c2e7d3-01e5-803c-bbf5-c6548791f6f1" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple">e.g. email → vector of 16 features/dimensions</mark></li></ul><ul id="1292e7d3-01e5-80f4-89c0-d12b8aabe8a9" class="bulleted-list"><li style="list-style-type:disc">All feature vector&#x27;s are embeddings but not the converse.</li></ul><ul id="1292e7d3-01e5-801a-af95-f60aff3003d2" class="bulleted-list"><li style="list-style-type:disc">f.v. each comp is a distinct part of object (not for embedding)</li></ul><p id="1292e7d3-01e5-802a-b08e-d17db5a07e9d" class=""><strong>Features, Notes</strong></p><ul id="1292e7d3-01e5-80fa-9605-c23b8a8a492d" class="bulleted-list"><li style="list-style-type:disc">The features that are <strong>useful</strong> depend on the application.</li></ul><ul id="1292e7d3-01e5-8067-86af-d7125d7577ab" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-default_background">If 2 features correlate highly, then you only need 1 of them. </mark></li></ul><hr id="1292e7d3-01e5-804d-be83-d245d920b9e9"/><p id="1292e7d3-01e5-807b-b23b-cd762f903124" class=""><strong>Typical ML Solution: </strong></p><ol type="1" id="1292e7d3-01e5-80c3-8e01-f7a4775c45e3" class="numbered-list" start="1"><li>Acquire data (Training set of emails)</li></ol><ol type="1" id="1292e7d3-01e5-8007-b99e-f7cd7a9dbd0a" class="numbered-list" start="2"><li>Determine features and labels <ol type="a" id="1292e7d3-01e5-802d-aafb-c29d0bf708df" class="numbered-list" start="1"><li>labelling — needs to (at least in part) be done by hand (expensive). </li></ol></li></ol><ol type="1" id="1292e7d3-01e5-80d2-9dbc-caf0c39f1407" class="numbered-list" start="3"><li>Pick the <strong>architecture</strong> (class of model)<ol type="a" id="1292e7d3-01e5-8014-9270-f54eb39ffba7" class="numbered-list" start="1"><li>we will focus on <strong>logistic regression</strong></li></ol></li></ol><ol type="1" id="1292e7d3-01e5-8034-bdcc-dc09ec95f8e8" class="numbered-list" start="4"><li>Train the model</li></ol><ol type="1" id="1292e7d3-01e5-80f7-8df7-cdfe6840a2e7" class="numbered-list" start="5"><li>Repeat &amp; refine </li></ol><ol type="1" id="1292e7d3-01e5-8097-83e9-c0499aee9e4f" class="numbered-list" start="6"><li>Use the finished model on new examples</li></ol><hr id="1292e7d3-01e5-809c-9ab2-dc22bc8eb5a9"/><p id="1292e7d3-01e5-80dd-ae62-fe0532cdcf86" class=""><strong>What’s Important </strong></p><p id="1292e7d3-01e5-8053-ab26-c716921e0c2e" class="">It’s not picking the right architecture, its having the most data, of the highest quality.</p><ul id="1292e7d3-01e5-806f-86f6-cbaeef94fbee" class="bulleted-list"><li style="list-style-type:disc">the trained algorithm is more accurate w&#x27; more data</li></ul><ul id="1292e7d3-01e5-80c0-9312-ce864b660b2c" class="bulleted-list"><li style="list-style-type:disc">models tend to behave the same for a hige dataset</li></ul><hr id="1292e7d3-01e5-8024-bc16-f143d23345c7"/><p id="1292e7d3-01e5-80df-acce-c594fa02b457" class=""><strong>Labelling is expensive </strong></p><ul id="1292e7d3-01e5-803e-b550-e5c3b1906024" class="bulleted-list"><li style="list-style-type:disc">If you have to do it all by hand </li></ul><ul id="15c2e7d3-01e5-8035-9558-ffab0e444a8d" class="bulleted-list"><li style="list-style-type:disc"><strong>options: </strong><ul id="1292e7d3-01e5-8043-9ffe-fa40cdb72a0a" class="bulleted-list"><li style="list-style-type:circle"><strong>Bootstrapping</strong>: start from seed set with high confidence labels, wherever its confident, apply that to unlabeled data</li></ul><ul id="1292e7d3-01e5-80aa-ac44-f0e46864dd7d" class="bulleted-list"><li style="list-style-type:circle"><strong>Crowdsource: </strong>users can report spam, captcha</li></ul></li></ul><hr id="1292e7d3-01e5-80e4-99a7-f926b5f59b3a"/><p id="1292e7d3-01e5-80bb-bff0-ca91a01371bd" class=""><strong>Binary Classification as Building Blocks </strong></p><ul id="1292e7d3-01e5-806a-b309-d9376822737a" class="bulleted-list"><li style="list-style-type:disc">With multiple classes (non-binary classification), we can still use binary classification:<ul id="1292e7d3-01e5-8008-95af-c6fc5ff3c1fa" class="bulleted-list"><li style="list-style-type:circle">chain them (like a decision tree) </li></ul><ul id="1292e7d3-01e5-807d-af71-ebce9a9ff6a5" class="bulleted-list"><li style="list-style-type:circle">run in parallel, pick which ones most important</li></ul></li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0"><mark class="highlight-red"><strong>Gradient Descent</strong></mark></summary><div class="indented"><p id="15c2e7d3-01e5-80ad-a75e-fd09fca6b251" class=""><strong>What ?</strong><div class="indented"><figure id="1292e7d3-01e5-801e-a0d4-f1900622f97e" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><msub><mi>n</mi><mi>θ</mi></msub><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>l</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">argmin_{\theta}
\frac{1}{n}\sum^n_{i=1}l(f(x_i; \theta),y_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div></figure><ul id="15c2e7d3-01e5-8020-ad71-d81fa7ce8c3c" class="bulleted-list"><li style="list-style-type:disc"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></span><span>﻿</span></span> — model parameters</li></ul><ul id="15c2e7d3-01e5-8034-ae94-f0e6ba374d40" class="bulleted-list"><li style="list-style-type:disc">minimize the <strong>loss </strong><em>(a.k.a. error, entropy)</em> of our function over the parameters, on the training set: </li></ul></div></p><p id="13b2e7d3-01e5-80a6-bb29-f69d72478966" class=""><strong>How ?</strong><div class="indented"><p id="12e2e7d3-01e5-80c9-b031-d3ef12b7c415" class="">For each component of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></span><span>﻿</span></span>: </p><ul id="12e2e7d3-01e5-8009-b7a2-e89721c628cf" class="bulleted-list"><li style="list-style-type:disc">Compute: <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">▽</mi><mi>L</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>0</mn></msub></mrow></mfrac><mo>…</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mi>d</mi></msub></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\triangledown L=
\begin{bmatrix}
\frac{\partial L}{\partial w_0}
\dots
\frac{\partial L}{\partial w_d}

\end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord amsrm">▽</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.331em;vertical-align:-0.4155em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9155em;"><span style="top:-3.0354em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4509em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4155em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span></span><span>﻿</span></span></li></ul><ul id="12e2e7d3-01e5-80fe-92ff-f0c07c26c764" class="bulleted-list"><li style="list-style-type:disc">Update <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></span><span>﻿</span></span> (as to go “downhill”): <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>←</mo><mi>θ</mi><mo>−</mo><mi>γ</mi><mi mathvariant="normal">▽</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">\theta&#x27; \larr \theta -\gamma \triangledown L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord amsrm">▽</span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span></li></ul></div></p><p id="12e2e7d3-01e5-8044-a347-db898bd0cd68" class=""><strong>Notes</strong></p><ul id="12e2e7d3-01e5-801a-81a9-f660aed71118" class="bulleted-list"><li style="list-style-type:disc"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span><span>﻿</span></span> : <strong>learn rate</strong> (for a given step, how far along the gradient to walk)</li></ul><ul id="12e2e7d3-01e5-80e0-b6ee-d00671e3e957" class="bulleted-list"><li style="list-style-type:disc"><strong>Assume L(theta) &gt;= L(theta&#x27;)</strong><ul id="12e2e7d3-01e5-80be-98d3-ffa8905cd55d" class="bulleted-list"><li style="list-style-type:circle">we move as though the curve was a linear function</li></ul><ul id="12e2e7d3-01e5-8067-9c87-d3312b5d48fe" class="bulleted-list"><li style="list-style-type:circle">ie: as long as we are close to the last step, its like a straight line.</li></ul></li></ul><ul id="12e2e7d3-01e5-80d7-8a8b-cf0c770c0f63" class="bulleted-list"><li style="list-style-type:disc"><strong>Why average </strong><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span><span>﻿</span></span><strong> across the training set? </strong><ul id="12e2e7d3-01e5-8086-8570-fc096fca21f8" class="bulleted-list"><li style="list-style-type:circle">so we dont need to divide step size by n </li></ul><ul id="12e2e7d3-01e5-809e-97b0-d3e8679777e5" class="bulleted-list"><li style="list-style-type:circle">so that step-sizes are standardized ( dont depend on <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span>)</li></ul></li></ul><ul id="12e2e7d3-01e5-80d0-adae-fc9965add3c4" class="bulleted-list"><li style="list-style-type:disc"><strong>&quot;first order&quot; method:</strong><ul id="12e2e7d3-01e5-8064-b773-c63973817849" class="bulleted-list"><li style="list-style-type:circle">uses local linear approximations. </li></ul><ul id="12e2e7d3-01e5-809e-b764-de4e26b99736" class="bulleted-list"><li style="list-style-type:circle"><strong>prone to getting stuck in local min.</strong></li></ul></li></ul><ul id="12e2e7d3-01e5-80a5-b1ef-f7454caa0106" class="bulleted-list"><li style="list-style-type:disc"><strong>Why not use a “second order” method? </strong><ul id="12e2e7d3-01e5-804e-a9f6-feaa71812fca" class="bulleted-list"><li style="list-style-type:circle">involves calculating the Hessian; partial derivative between every 2 pairs of features.</li></ul><ul id="12e2e7d3-01e5-805d-9aa3-de5a0e9a3281" class="bulleted-list"><li style="list-style-type:circle">Increases exponentially with dimensionality.</li></ul></li></ul><ul id="12e2e7d3-01e5-80fc-acce-ddbaee679e8d" class="bulleted-list"><li style="list-style-type:disc">&quot;<strong>hyper-params</strong>&quot;<ul id="15c2e7d3-01e5-80b1-add1-f4e987c7fe26" class="bulleted-list"><li style="list-style-type:circle">Stuff that&#x27;s not trained, but affects the model. </li></ul><ul id="12e2e7d3-01e5-8017-bb2e-d3a61cb7fddd" class="bulleted-list"><li style="list-style-type:circle">e.g. <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span><span>﻿</span></span></li></ul></li></ul><ul id="12e2e7d3-01e5-8064-a545-dc11c776bb57" class="bulleted-list"><li style="list-style-type:disc"><strong>Pros of a high learn-rate:</strong> <ul id="12e2e7d3-01e5-806f-a986-faf1633d26b8" class="bulleted-list"><li style="list-style-type:circle">you&#x27;ll jump over small drops.</li></ul><ul id="12e2e7d3-01e5-808e-af5a-fde5c5ba33b9" class="bulleted-list"><li style="list-style-type:circle">Ideally, initialize L.R high, and as iterations continue it goes towards zero.</li></ul></li></ul><p id="12e2e7d3-01e5-804a-a850-f41d9e69fe09" class=""><strong>Prevent Getting Stuck</strong><div class="indented"><ol type="1" id="973bdd79-316b-43ca-a297-3532b2cb4b5c" class="numbered-list" start="1"><li><strong>Momentum:</strong><ul id="0627cd86-e2f8-4fd1-91f3-775d734f2596" class="bulleted-list"><li style="list-style-type:disc">before: <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>−</mo><mi>γ</mi><mi mathvariant="normal">▽</mi><mi>L</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w = w - \gamma \triangledown L(w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord amsrm">▽</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span><ul id="9c720dcf-dec5-4793-bdd4-4756bf7ca9cb" class="bulleted-list"><li style="list-style-type:circle">let <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>L</mi><mo>=</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">\Delta L = D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span><span>﻿</span></span></li></ul><ul id="1d5542f4-2c5a-4341-a046-4ea5c9279e93" class="bulleted-list"><li style="list-style-type:circle">new <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mn>0.9</mn><mi>D</mi><mo>−</mo><mi mathvariant="normal">Δ</mi><mi>L</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D&#x27; = 0.9 D - \Delta L (w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">0.9</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span><ul id="625ceb00-5015-466c-baa1-d4ea3850f22d" class="bulleted-list"><li style="list-style-type:square">instead of jumping in opposite direction, curve towards the new downhill</li></ul><ul id="df47d12c-7774-41b7-b6e6-a7c3361d2c73" class="bulleted-list"><li style="list-style-type:square">prevents it from getting caught in a small dip</li></ul><ul id="4eb994c1-2e2e-4ac4-b4dc-a04a263d2625" class="bulleted-list"><li style="list-style-type:square">&quot;momentum&quot; is built up over iterations.</li></ul></li></ul></li></ul></li></ol><ol type="1" id="1ea0b52c-4c30-44e5-93b7-c7ec983a4e6f" class="numbered-list" start="2"><li><strong>Stochastic Gradient Descent:</strong><ul id="3477c855-cb39-497d-b568-810e6950b44b" class="bulleted-list"><li style="list-style-type:disc">instead of average loss over whole train-set, take average over a <span style="border-bottom:0.05em solid">random subset</span></li></ul></li></ol></div></p><h2 id="12e2e7d3-01e5-80ee-8270-d35ae1a35b05" class=""><mark class="highlight-orange"><strong>Minimize Loss </strong></mark></h2><figure id="12e2e7d3-01e5-8061-b479-ce61f2b62c4b" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mi>t</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">l(y,t)=\frac{1}{2}(y-t)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></div></figure><ul id="12e2e7d3-01e5-803e-9a62-dc5e508448d4" class="bulleted-list"><li style="list-style-type:disc"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span> = true value, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>w</mi><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y=w\cdot x + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span><span>﻿</span></span><ul id="12e2e7d3-01e5-8088-b163-c9d15ba7271e" class="bulleted-list"><li style="list-style-type:circle"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span><span>﻿</span></span> can be a range of values, otherwise, since <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo separator="true">,</mo><mi>y</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t,y\in (0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> ⇒ the gradient is flat or undefined, so can’t be descended</li></ul></li></ul><ul id="13b2e7d3-01e5-8013-b864-fb11fa02075f" class="bulleted-list"><li style="list-style-type:disc">The 1/2 is to make taking the derivative easier (2&#x27;s cancel out)</li></ul><p id="13b2e7d3-01e5-8073-b82b-d139bd3f96d6" class="">To make loss <strong>bounded</strong>, use the <strong>sigmoid function</strong>: </p><figure id="12e2e7d3-01e5-80fd-b6be-cc4491dcd888" class="equation"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><mi>z</mi></msup><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mi>z</mi></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(z)=\frac{e^z}{1+e^z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1107em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5904em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div></figure><ul id="12e2e7d3-01e5-80e9-9fe2-f32a54de4ed8" class="bulleted-list"><li style="list-style-type:disc">clamps a value <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span></span><span>﻿</span></span> between 0 and 1, without any discontinuity</li></ul><ul id="12e2e7d3-01e5-80a1-9f05-e6c6357accd7" class="bulleted-list"><li style="list-style-type:disc">This cant have 0 loss, or 1 loss. so we can never exactly match the correct labels. but can be pretty close.</li></ul><ul id="12e2e7d3-01e5-80da-9eb1-e860747e935d" class="bulleted-list"><li style="list-style-type:disc">Its derivative is also simple to take: <figure id="12e2e7d3-01e5-80b5-a946-fd08a6e00733" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.11.16.png"><img style="width:192px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.11.16.png"/></a></figure></li></ul><hr id="12e2e7d3-01e5-808d-8551-d7d191209c58"/><p id="12e2e7d3-01e5-80fc-b0db-e398892c431d" class="">Now we can do gradient descent: </p><ul id="12e2e7d3-01e5-8087-ad1c-c31b67abce4b" class="bulleted-list"><li style="list-style-type:disc">For every weight, we want the partial derivative w&#x27; respect to <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span><ul id="12e2e7d3-01e5-8062-943a-cc55827f31b5" class="bulleted-list"><li style="list-style-type:circle">the gradient is the vector of all of these, for each feature and weight position.</li></ul></li></ul><hr id="12e2e7d3-01e5-8026-902a-da4099252ea5"/><p id="12e2e7d3-01e5-80a4-a672-deb6a7e7cfd7" class=""><strong>Summary:</strong></p><ul id="12e2e7d3-01e5-807b-958a-c670d7f266aa" class="bulleted-list"><li style="list-style-type:disc">We now have a logistic regression model (our linear model fed into the logistic function).</li></ul><ul id="12e2e7d3-01e5-809e-8091-d5097f34f2ed" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-yellow_background">we&#x27;re still assuming independence between words (features).</mark></li></ul><h2 id="15c2e7d3-01e5-80e7-b23d-eba196473cdb" class=""><mark class="highlight-orange"><strong>Implementing Gradient Descent</strong></mark></h2><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><mark class="highlight-default"><strong>V1 — Batch Gradient Descent </strong></mark></summary><div class="indented"><p id="13b2e7d3-01e5-80fb-9024-eef90d5995fd" class="">Iterative algorithm ⇒ poor use of MapReduce, slightly better for <strong>Spark</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="13b2e7d3-01e5-80ce-b118-c8fcba2a15b7" class="code"><code class="language-Scala">// map our loss function onto an RDD
val points = spark.textFile(...).map(...).cache()
var w = ... // initial vector (w is held on driver&#x27;s memory)
for(i=1 to MAX_ITERATIONS) {
		val gradient = points.map{ p =&gt;
				p.x * (1/(1+exp(-p.y*(w dot p.x)))-1)*p.y
		}
		// Add up all vectors to get the gradient.
		.reduce((a,b) =&gt; a+b)
		// Update set of weights
		w -= gradient * LR
}
// dividing by n missing</code></pre><p id="12e2e7d3-01e5-8013-9615-d067aae95277" class=""><mark class="highlight-red_background"><strong>Problem</strong></mark><strong>: </strong>may require too much memory</p><p id="12e2e7d3-01e5-8049-9d89-c9e30b041e0e" class=""><strong>Solution: </strong>online (stochastic) gradient descent</p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">V2 — Ensemble Learning </summary><div class="indented"><ul id="13b2e7d3-01e5-80ff-9201-f7bfe38628e5" class="bulleted-list"><li style="list-style-type:disc">Divide dataset into <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span><span>﻿</span></span> partitions — 1 per. worker to (independently) train a model (without shuffling to the driver). </li></ul><ul id="12e2e7d3-01e5-8083-9c2b-c66adb78eca5" class="bulleted-list"><li style="list-style-type:disc">Then, combine the models in <span style="border-bottom:0.05em solid">some way</span> to make a final prediction:<ul id="12e2e7d3-01e5-809b-af11-d9c20d019013" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-red"><strong>Majority Vote</strong></mark><ol type="1" id="15c2e7d3-01e5-80b9-8fe1-e44f1439a3ce" class="numbered-list" start="1"><li>Get each models output <ul id="15c2e7d3-01e5-805a-8767-f9eccb8c5315" class="bulleted-list"><li style="list-style-type:disc">Apply the logistic function to the continuous output for each model individually</li></ul></li></ol><ol type="1" id="15c2e7d3-01e5-80d1-908e-ccaeb5e47084" class="numbered-list" start="2"><li>Take a majority vote<ul id="13b2e7d3-01e5-80cf-8cd8-ced04264172c" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-default">For an EVEN # models ⇒ need weighted voting since a TIE is possible. </mark></li></ul></li></ol></li></ul><ul id="12e2e7d3-01e5-80fa-b1bc-d4de14b629e1" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-teal"><strong>Weighted Voting </strong></mark><em><mark class="highlight-teal">(more parallel)</mark></em><ol type="1" id="15c2e7d3-01e5-804d-98a7-c64bbfd349cc" class="numbered-list" start="1"><li>AVERAGE the (continuous) values returned by each model</li></ol><ol type="1" id="15c2e7d3-01e5-8073-9ec2-cb001a53795b" class="numbered-list" start="2"><li>THEN apply the logistic function. </li></ol></li></ul></li></ul><p id="12e2e7d3-01e5-80d7-8de3-ed33626b0605" class="">
</p><figure id="13b2e7d3-01e5-801d-b86d-ca04ea640521" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_10.33.03.png"><img style="width:384px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_10.33.03.png"/></a></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13b2e7d3-01e5-802d-aba4-f12eab177215"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="38d0a96a-5b3b-40c0-a0f3-9b50986ca345" class=""><strong>Benefits of the Ensemble</strong></p><p id="13b2e7d3-01e5-807f-83ca-cb8b38ded3ee" class="">We ASSUME that errors are not CORRELATED. For example, if all the models got trapped at a local minimum, that would be bad. But, if we assume that errors are not correlated, then the chance of this happening is low. </p><p id="13b2e7d3-01e5-801e-9c16-fc432de6e713" class="">That being said, the benefits are: </p><ul id="12e2e7d3-01e5-8097-a9ac-d2d89d2a49f1" class="bulleted-list"><li style="list-style-type:disc">Less likely that all models make the wrong predictions. </li></ul><ul id="12e2e7d3-01e5-8007-82cb-e0d87aaaa8cd" class="bulleted-list"><li style="list-style-type:disc">Reduces the VARIANCE of the results across different datasets. </li></ul></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13b2e7d3-01e5-80e9-9899-fc74d4620823"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="56dd1624-db2c-4e4b-84a6-f4f0bc1b6646" class=""><strong># models improves accuracy TO AN EXTENT </strong></p><p id="13b2e7d3-01e5-8051-8cb1-e057d46b4bf5" class="">We stop improving at a certain point. <em>(Why? If a model has an output nobody else has, it gets outvoted. The more you have, the less they can make themselves heard)</em></p><figure id="13b2e7d3-01e5-80a6-b268-df325bbf7612" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.18.48.png"><img style="width:336px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.18.48.png"/></a></figure><p id="13b2e7d3-01e5-807c-9bd1-fd7348bb17a3" class="">
</p></div></figure></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Online (</strong><strong>Stochastic</strong><strong>) Gradient Descent </strong></summary><div class="indented"><p id="13b2e7d3-01e5-8084-b3fb-ca27000cbb18" class=""><strong>Online Learning: </strong>data is given one point at a time. </p><p id="13b2e7d3-01e5-8004-88bb-cbc24f3e7709" class="">⇒ Instead of taking the average gradient over a set of points and taking your step based on that gradient, compute the gradient AND take a step for a single data point. </p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13b2e7d3-01e5-80e7-a60b-d896f562441f"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="034171e8-14fb-4600-abdb-2b1edd91c36b" class=""><strong>Note: </strong>although each step might appear to be going in a different direction, ON AVERAGE the amount we move will be the same as with the offline case </p></div></figure><h3 id="13b2e7d3-01e5-80d3-a961-ed0a07f7d30f" class=""><strong>For an Ensemble</strong></h3><figure id="12e2e7d3-01e5-803b-ac3a-c3414949fe36" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.17.57.png"><img style="width:288px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.17.57.png"/></a></figure><p id="13b2e7d3-01e5-802f-a8dc-f8bcbf3f49e9" class=""><code>Mapper</code></p><ul id="13b2e7d3-01e5-8037-85f8-e82b059efd93" class="bulleted-list"><li style="list-style-type:disc">Setup(): initialize <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span></span><span>﻿</span></span></li></ul><ul id="13b2e7d3-01e5-8039-9912-e626182cb101" class="bulleted-list"><li style="list-style-type:disc">Map(): computes the gradient &amp; updates the weight vector. </li></ul><ul id="13b2e7d3-01e5-80e5-ad21-e9e913bbc450" class="bulleted-list"><li style="list-style-type:disc">Cleanup(): output the model(s) </li></ul><p id="13b2e7d3-01e5-80ca-8ecd-eea6fc71a5c8" class=""><em><mark class="highlight-gray">* map() is called only ONCE for each point (single pass through dataset)</mark></em></p><h3 id="13b2e7d3-01e5-80c7-9e8a-c40cd1a22cb6" class="">For ONE Model</h3><figure id="12e2e7d3-01e5-8061-ad8e-dd78d035d687" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.18.45.png"><img style="width:288px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-10-29_at_18.18.45.png"/></a></figure><p id="13b2e7d3-01e5-80d6-8091-f44a1aa8af69" class=""><code>Mapper </code></p><p id="13b2e7d3-01e5-806b-a840-d8c1b7c852f0" class="">Parses the strings (of the text file) and emits (feature, label) pairs (feature vectors)</p><p id="13b2e7d3-01e5-8054-ba01-f176656bf581" class=""><code>Reducer </code></p><p id="13b2e7d3-01e5-80e5-aeec-da9aaeafdb7c" class=""><mark class="highlight-gray">Same as the ensemble-mapper </mark></p><ul id="13b2e7d3-01e5-805c-8419-de028039b936" class="bulleted-list"><li style="list-style-type:disc">Setup(): initialize <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span></span><span>﻿</span></span></li></ul><ul id="13b2e7d3-01e5-809d-898c-efd0c178f3e9" class="bulleted-list"><li style="list-style-type:disc">Map(): do 1 gradient step</li></ul><ul id="13b2e7d3-01e5-804f-99c8-f79d0edce7ea" class="bulleted-list"><li style="list-style-type:disc">Cleanup(): <mark class="highlight-yellow_background">“generates output” </mark><p id="13b2e7d3-01e5-803a-b934-eed94f498608" class=""><em><mark class="highlight-gray">as long as we set the # reducers to 1, then 1 model is output. </mark></em></p></li></ul></div></details><hr id="15c2e7d3-01e5-8019-93af-dd59caec3b7d"/></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0"><mark class="highlight-red">Evaluating a Model</mark></summary><div class="indented"><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Overfitting</summary><div class="indented"><p id="13b2e7d3-01e5-8025-800d-f1906bfe2fc0" class="">The problem with overfitting:<div class="indented"><p id="13b2e7d3-01e5-8090-806d-ea8f8ccadca1" class="">It’s not enough to say that minimized loss ⇒ best model. An <strong>overfit</strong> model can have 0 loss, but still be useless. Loss is a measure of “how closely does it match the <strong>training data</strong>”, but we don’t care about the training data, we care about new, unseen data.</p><blockquote id="13b2e7d3-01e5-8049-99cb-fe17f5dabbec" class="">“Once a metric becomes a target, it stops becoming useful as a metric” </blockquote><p id="13b2e7d3-01e5-8037-bdce-eb053af06032" class="">The <strong>bigger</strong> the training set, the more “representative” a model is ⇒ <strong>big data </strong>! </p></div></p><p id="13b2e7d3-01e5-8089-a48c-cb396087f7bc" class="">Solutions to Overfitting </p><ol type="1" id="13b2e7d3-01e5-80e6-b8de-da60d0c8d14b" class="numbered-list" start="1"><li>Regularization (we won’t cover) </li></ol><ol type="1" id="13b2e7d3-01e5-80e8-a40e-d65bcb7e6671" class="numbered-list" start="2"><li><strong>Checkpointing</strong><p id="13b2e7d3-01e5-8027-b6d3-c6c520753802" class="">Every <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></span><span>﻿</span></span> epochs write the current weight-vector to disk.</p><ul id="13b2e7d3-01e5-8031-a5aa-cdcfe1e6e380" class="bulleted-list"><li style="list-style-type:disc">“<strong>Epoch” — </strong>a single pass through the training data (training iteration). </li></ul><ul id="13b2e7d3-01e5-801f-bed7-c2c212022a4c" class="bulleted-list"><li style="list-style-type:disc"><strong>Tradeoff: </strong> smaller <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span></span><span>﻿</span></span> ⇒ better information gained ⇒ more space used</li></ul><p id="13b2e7d3-01e5-805d-b0d8-d44e67f3953d" class="">Then, using a model with one of these weight-vectors, you can find it’s loss on a <em>validation set</em>. </p><p id="13b2e7d3-01e5-80c9-a9ac-e431b9d186d2" class="">Why this works? Eventually, the training-loss will always decrease, but the validation loss will plateau at some point. That’s essentially where you would stop as it more accurately represents general data.  </p></li></ol><p id="13b2e7d3-01e5-8032-a0b0-ce13db7f96aa" class="">
</p><p id="13b2e7d3-01e5-8015-b7f6-e0f2899ce1b1" class="">
</p><p id="13b2e7d3-01e5-8071-8ad2-e845632bd7fe" class="">
</p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Performance Metrics (ROCA)</summary><div class="indented"><p id="13b2e7d3-01e5-8063-a6fc-c7a849b4732c" class="">Being “wrong” is not equal in both cases</p><ul id="13b2e7d3-01e5-804c-af42-c29261827505" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple">e.g. (Spam Email) Labelling a legit email as spam is WORSE than a spam email as legit. </mark></li></ul><h3 id="13b2e7d3-01e5-80a7-a9f7-cd8bd988ac99" class=""><strong>4 Metrics</strong></h3><ol type="1" id="13b2e7d3-01e5-8078-a92a-e4d6fff18291" class="numbered-list" start="1"><li>precision</li></ol><ol type="1" id="13b2e7d3-01e5-80e9-8bae-fb0ac68568fc" class="numbered-list" start="2"><li>miss-rate </li></ol><ol type="1" id="13b2e7d3-01e5-8088-97f1-f60c879885d2" class="numbered-list" start="3"><li>recall (True Positive Rate)</li></ol><ol type="1" id="13b2e7d3-01e5-80f2-bb15-e07a267c3106" class="numbered-list" start="4"><li>fall-out (False Positive Rate)</li></ol><figure id="13b2e7d3-01e5-80e3-9aca-ed65873dbdf0" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.36.30.png"><img style="width:288px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.36.30.png"/></a></figure><h3 id="13b2e7d3-01e5-80fa-8f94-e4855b33cc3b" class="">2 Key Metric Graphs</h3><p id="13b2e7d3-01e5-80a5-8425-d9c56bb236ca" class="">(RECALL) Our models return a contin<strong>u</strong>ous value, and we use some <strong>threshold </strong>to determine the class (<mark class="highlight-purple">e.g. value &gt; 0.5 ⇒ spam</mark>). </p><p id="13b2e7d3-01e5-807e-9214-d4230137dda1" class="">In both cases, illustrates how the “performance” of a binary classifier changes as you vary the <strong>threshold</strong>. </p><ol type="1" id="13b2e7d3-01e5-800b-8b83-ecf2ae78fb97" class="numbered-list" start="1"><li><strong>ROC Curve </strong></li></ol><ul id="13b2e7d3-01e5-808b-97c0-d63e043cbb61" class="bulleted-list"><li style="list-style-type:disc">Graph Recall vs. Fall-Out</li></ul><ul id="13b2e7d3-01e5-803a-b1ea-d97b9fc3bc84" class="bulleted-list"><li style="list-style-type:disc">As you vary the threshold, how many more false positives slip in, and how many more true positives are successfully found.</li></ul><ul id="13b2e7d3-01e5-80ae-b1a5-ef0944012af6" class="bulleted-list"><li style="list-style-type:disc">Examples: <ul id="13b2e7d3-01e5-8052-9204-f6e9f0f2bab9" class="bulleted-list"><li style="list-style-type:circle">threshold = 1 ⇒ only classify an email as spam if &gt; 1 ⇒ classify ALL emails as legit ⇒ FP rate is 0%, FN rate = 100%</li></ul><ul id="13b2e7d3-01e5-8068-aae2-e8037b1238c7" class="bulleted-list"><li style="list-style-type:circle">threshold = 0 ⇒ only classify an email as spam if &gt; 0 ⇒ classify ALL emails as spam ⇒ FP rate is 100%, FN rate is 100%</li></ul></li></ul><figure id="13b2e7d3-01e5-809a-ab19-c01d144d6f73" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.45.17.png"><img style="width:240px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.45.17.png"/></a><figcaption>A2 is better if we want a higher false positive rate. </figcaption></figure><ol type="1" id="13b2e7d3-01e5-80ca-b241-f8c9b00da8e3" class="numbered-list" start="2"><li><strong>PR Curve </strong><ul id="13b2e7d3-01e5-80a9-a49f-d15bbeb195e6" class="bulleted-list"><li style="list-style-type:disc">Recall vs. Precision </li></ul><figure id="13b2e7d3-01e5-80e8-ab9e-c2a4054b46e8" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.49.32.png"><img style="width:288px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_11.49.32.png"/></a></figure></li></ol><p id="13b2e7d3-01e5-80fd-a176-daa4d4f845a9" class=""><strong>ROCA</strong></p><ul id="13b2e7d3-01e5-809d-ba55-e1367291fb5a" class="bulleted-list"><li style="list-style-type:disc">Area under the ROC curve.</li></ul><ul id="13b2e7d3-01e5-80c9-9f20-fc7c9b6f591f" class="bulleted-list"><li style="list-style-type:disc">Represents threshold invariant accuracy</li></ul><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="13b2e7d3-01e5-80f7-bbe0-d77fa229f9c3"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark-double_gray.svg"/></div><div style="width:100%"><p id="26d324f0-5a44-48d3-8b70-2bfcf1e1b604" class=""><strong>ROCA == 0.5 is the “worst you can get” </strong></p><ul id="13b2e7d3-01e5-8004-a5bd-daa63f65f9bf" class="bulleted-list"><li style="list-style-type:disc">If ROCA == 1, the predictor is perfect. Regardless of threshold, the false positive rate is 0%, true positive rate is 100%. </li></ul><ul id="13b2e7d3-01e5-80d9-8f62-de83849698d4" class="bulleted-list"><li style="list-style-type:disc">If ROCA == 0, the predictor is always wrong. HOWEVER, to get a perfect predictor, all you have to do is use the opposite of it’s predictions. </li></ul><ul id="13b2e7d3-01e5-80f2-b267-e270b349f972" class="bulleted-list"><li style="list-style-type:disc">If ROCA == 0.5, the prediction is a <strong>random chance</strong></li></ul><p id="13b2e7d3-01e5-80d5-bd3d-e87e57800e92" class="">The worst ROC is a straight line; the classifier’s predictions don’t correlate at all with the label. Increasing the </p></div></figure><h3 id="13b2e7d3-01e5-80a1-80d7-e69841b38381" class="">Summary </h3><ul id="13b2e7d3-01e5-807d-9ebe-ffbbed1298f0" class="bulleted-list"><li style="list-style-type:disc">Don’t use accuracy as a metric, use the ROC curve. </li></ul><ul id="13b2e7d3-01e5-8097-a6fc-d803e079ada1" class="bulleted-list"><li style="list-style-type:disc">Specifically, to put a number to it, get the ROCA, which represents accuracy* (in a way)</li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><strong>Testing a Model</strong></summary><div class="indented"><ul id="13b2e7d3-01e5-8009-8b15-eb0577ac9648" class="bulleted-list"><li style="list-style-type:disc">Step 1: Offline training and evaluation (holdout, cross-validate, etc)<ul id="13b2e7d3-01e5-8017-9c2c-f84ad07fa833" class="toggle"><li><details open=""><summary><strong>K-Fold Cross Validation</strong></summary><p id="13b2e7d3-01e5-80c2-971f-f7ca5e9c1737" class=""><strong>Purpose</strong></p><ul id="13b2e7d3-01e5-8013-820d-f7ed0d3e59df" class="bulleted-list"><li style="list-style-type:disc">To prevent overfitting, you need more training data. But you also need separate test data. This method let’s you keep most of your data for training while also testing. </li></ul><ul id="13b2e7d3-01e5-8041-906d-e1430f44d1cb" class="bulleted-list"><li style="list-style-type:disc">It ALSO gives you confidence wether or not your <strong>method</strong> (NOT a specific model, but your training algorithm itself) will work on typical datasets. </li></ul><p id="13b2e7d3-01e5-80ca-93b0-d692f1a1ad36" class=""><strong>How</strong></p><ul id="13b2e7d3-01e5-8066-8700-ce8e87320000" class="bulleted-list"><li style="list-style-type:disc">Divide data into <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span><span>﻿</span></span> subsets</li></ul><ul id="13b2e7d3-01e5-8087-97ee-e45a2e6c6920" class="bulleted-list"><li style="list-style-type:disc">For each subset, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span>: <ul id="13b2e7d3-01e5-80c2-abc1-dfede498358d" class="bulleted-list"><li style="list-style-type:circle">train on all other sets</li></ul><ul id="13b2e7d3-01e5-805d-9bb4-f4776d213347" class="bulleted-list"><li style="list-style-type:circle">test on subset <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> </li></ul></li></ul><figure id="13b2e7d3-01e5-801f-a156-ecc8053c1f09" class="image" style="text-align:center"><a href="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_12.29.32.png"><img style="width:288px" src="06%20%E2%80%94%20ML%20Part%201%20(Data%20Mining)%201292e7d301e58007842dfd6f7cfd975a/Screenshot_2024-11-11_at_12.29.32.png"/></a><figcaption><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">k=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span></span><span>﻿</span></span></figcaption></figure><p id="13b2e7d3-01e5-8064-b94f-fe170ad8dfad" class=""><strong>Interpreting the Results</strong></p><p id="13b2e7d3-01e5-803d-91e7-f4da9175847a" class="">If you get similar accuracy for every iteration, you can be confident that your model is not overfit. Otherwise, there’s high variance between training-sets. </p></details></li></ul></li></ul><ul id="13b2e7d3-01e5-80d2-a6e1-d3c435548cd8" class="bulleted-list"><li style="list-style-type:disc">Step 2: A/B testing vs other methods<ul id="13b2e7d3-01e5-80d6-be49-f9f5baaaebb6" class="toggle"><li><details open=""><summary><strong>AB Testing </strong></summary><ul id="13b2e7d3-01e5-80e1-9505-cdb72ee74b44" class="bulleted-list"><li style="list-style-type:disc">You can use this to compare different feature selection methods or compare to current best-practice models.</li></ul><ul id="15c2e7d3-01e5-80bf-b1a3-d3e563b94235" class="bulleted-list"><li style="list-style-type:disc">e.g. Layout changes on a website. You want to know what users think without telling them you’ve made changes. You only show the layout changes for a specific group of people, group B. Then they see how they react / how their behavior changed. </li></ul></details></li></ul></li></ul></div></details></div></details><hr id="13b2e7d3-01e5-80ef-a61d-de91a30a9e5a"/><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0"><mark class="highlight-purple">Sentiment Analysis Case Study </mark></summary><div class="indented"><p id="13b2e7d3-01e5-8003-85c5-f43064c1cabf" class="">How the training data was produced: </p><ul id="13b2e7d3-01e5-807a-955c-dc07b45649c6" class="bulleted-list"><li style="list-style-type:disc">Tweets were labeled as “positive” | “negative” based on emojis used. </li></ul><ul id="13b2e7d3-01e5-802f-9355-e8e365d772e9" class="bulleted-list"><li style="list-style-type:disc">The emojis were removed, leaving just text. <ul id="13b2e7d3-01e5-802b-b9ca-d19d1cde3c1a" class="bulleted-list"><li style="list-style-type:circle"><em><mark class="highlight-gray">Why? since The labels are based on emoji content in the tweet, removing them prevents the classifier from noticing the correlation so that it can focus on the language content. </mark></em></li></ul></li></ul><ul id="13b2e7d3-01e5-808b-9be1-f31ce8b71dc6" class="bulleted-list"><li style="list-style-type:disc">As feature-vectors: “byte level” 4-grams<ul id="13b2e7d3-01e5-8089-aec9-d96fc939aa8d" class="bulleted-list"><li style="list-style-type:circle">Each vector looks like: [0 1 0 1 1 … 0 1 0]. Position <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> indicates that the tweet does (=1) or does not (=1) contain 4-gram # <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span>. <p id="13b2e7d3-01e5-80cf-93f0-f96d7fabe040" class="">e.g. for text “Hello there”, the 4-grams would be: “Hell”, “ello”, “llo_”, “lo_t”, …  </p></li></ul></li></ul></div></details><p id="13b2e7d3-01e5-8003-b443-fbec392e4918" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"><hr/><details open="" style="padding-top:1em"><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Inline comments</summary><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><strong>Stochastic</strong></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/ALm5wu2D7opyGPhg1IC5ZBqM5ZYIOR8MwAIakj3yS20lKw=s100" class="icon user-icon"/><span><b>roman hudaj</b> <time style="font-size:0.8em">Nov 11, 2024, 10:59 AM</time></span></span></div><div style="padding:0.2em">what part of this is stochastic? </div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><strong>Momentum:</strong></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/ALm5wu2D7opyGPhg1IC5ZBqM5ZYIOR8MwAIakj3yS20lKw=s100" class="icon user-icon"/><span><b>roman hudaj</b> <time style="font-size:0.8em">Dec 14, 2024, 5:08 PM</time></span></span></div><div style="padding:0.2em">we won’t look into this further.</div><div style="padding:0.3em"></div></li></ul></div><hr/></div></details></span></body></html>