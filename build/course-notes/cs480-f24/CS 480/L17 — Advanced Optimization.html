<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>L17 — Advanced Optimization</title><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/></head><body><article id="15e2e7d3-01e5-8032-b9cf-eb02a13f37b6" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/document_blue.svg"/></div><h1 class="page-title">L17 — Advanced Optimization</h1><p class="page-description"></p></header><div class="page-body"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1602e7d3-01e5-803c-833d-e19ea161e945"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark_gray.svg"/></div><div style="width:100%"><p id="e615b8ab-dcc6-419a-ad6c-acfa007a537b" class=""><strong>L17 — To Know</strong></p><hr id="dd607246-2f53-4531-84e1-4a5493f4abe1"/><ul id="c4525f31-87e4-4b16-8341-9c7549607d7c" class="toggle"><li><details open=""><summary>Defend the need for <strong>symmetry-breaking</strong> in a neural network.</summary><p id="0d953602-4bfd-42ea-8eab-1a11d56b6d0a" class=""><strong>Symmetry breaking</strong> is necessary in neural networks because if all weights are the same, it&#x27;s as if there is only one hidden layer. Randomly chosen initial parameters can break this symmetry.</p></details></li></ul><ul id="594336c1-1763-4006-97f2-210e102f46eb" class="toggle"><li><details open=""><summary>Recall three weight initialization strategies for neural networks.</summary><ul id="4a4d2fa8-26e3-4a97-9549-727c6417e0ae" class="bulleted-list"><li style="list-style-type:disc"><strong>Standard initialization</strong>, which can cause activations to explode when going forward and vanishing gradients when going backwards.</li></ul><ul id="43460b10-30ad-4ab1-81cd-3cfe4129eec4" class="bulleted-list"><li style="list-style-type:disc"><strong>Xavier initialization</strong>, which draws weights from a Gaussian (or normal) distribution to maintain a balanced flow both forward and backward through the layers, avoiding vanishing and exploding gradients.</li></ul><ul id="7d98cf66-e763-4741-9f25-77702fe07162" class="bulleted-list"><li style="list-style-type:disc"><strong>Bias initialization</strong>, which is typically zero for hidden layers, but depends on the data for the output layer (e.g., a bias towards the most common class).</li></ul></details></li></ul><ul id="0fe1a760-2ea9-452a-8434-b981385b4b06" class="toggle"><li><details open=""><summary>Use appropriate initialization strategies to break symmetry prior to optimization.</summary><ul id="0a7956e9-aad0-4c78-b79a-b928bfaff4e3" class="bulleted-list"><li style="list-style-type:disc"><strong>Xavier initialization</strong> is a good way to break symmetry before optimization.</li></ul></details></li></ul><ul id="d4cba35b-c5d8-4947-aafa-4b26eb6f9efd" class="toggle"><li><details open=""><summary>Defend the need for <strong>momentum</strong>- and/or <strong>adaptive learning rate</strong> based optimization<br/>with reference to the limitations of stochastic gradient descent and the<br/>conditioning of the loss-landscape.<br/></summary><ul id="e498585d-36b0-4824-aa57-899585606642" class="bulleted-list"><li style="list-style-type:disc"><strong>Momentum and adaptive learning rate</strong> based optimization are needed because:<ul id="291c85ae-fa66-419a-bd85-e446e8d167ce" class="bulleted-list"><li style="list-style-type:circle">Stochastic gradient descent (SGD) can be inefficient, and zig-zag from high loss to low loss.</li></ul><ul id="1a55e2dd-ca38-4c0b-a417-54f2e0f6ae17" class="bulleted-list"><li style="list-style-type:circle">Small step sizes lead to slow convergence while large step sizes can cause overshooting.</li></ul><ul id="f70f1835-35cf-40da-ae73-018f84da6330" class="bulleted-list"><li style="list-style-type:circle">Loss landscapes can be rugged, causing the optimizer to move up and down instead of directly towards the minimum.</li></ul><ul id="6a5565db-9657-45a5-b2d0-7ce5a208526a" class="bulleted-list"><li style="list-style-type:circle">Adaptive learning rates also help when gradients have different scales across layers, and hence have unequal number of inputs.</li></ul></li></ul></details></li></ul><ul id="6253ec9e-38b0-4345-911c-58ff85f24a99" class="toggle"><li><details open=""><summary>What are the gradient update equations for major momentum- and/or adaptive learning rate based optimization techniques (Momentum, Adagrad, RMSProp, Adam).</summary><ul id="24d3a570-e91f-4104-beb8-199b103aaf7b" class="bulleted-list"><li style="list-style-type:disc"><strong>Momentum:</strong> The velocity at time <em>t</em> depends on the current gradient as well as the past, controlled by a parameter.</li></ul><ul id="6e3b0503-655d-46ae-9cc7-425d8b2e4865" class="bulleted-list"><li style="list-style-type:disc"><strong>AdaGrad:</strong> Adapts the learning rate for each parameter based on its history, decreasing the learning rate for parameters that frequently have large gradients.</li></ul><ul id="424b3be5-01a1-4ec2-9f1c-7aa263a8b245" class="bulleted-list"><li style="list-style-type:disc"><strong>RMSProp:</strong> Prevents the learning rate from getting too small too quickly by preventing old weights from contributing too highly to the sum.</li></ul><ul id="9799fdcd-4d2a-4f7b-8cdd-d509a0e67146" class="bulleted-list"><li style="list-style-type:disc"><strong>Adam:</strong> Uses gradient to estimate both momentum (first moment) and variance (second moment), with a bias correction for initial steps.</li></ul></details></li></ul><ul id="819384a5-da9b-4afb-9c61-b3ba50248a06" class="toggle"><li><details open=""><summary>Identify the strengths and limitations of different optimizers.</summary><ul id="9ade9244-9c1e-496f-9525-30332c347476" class="bulleted-list"><li style="list-style-type:disc"><strong>Stochastic Gradient Descent:</strong> simple but inefficient, especially with rugged loss landscapes.</li></ul><ul id="1b0047fd-0691-4e93-8819-aff5547229da" class="bulleted-list"><li style="list-style-type:disc"><strong>Momentum:</strong> Tries to optimize the tradeoff between stability and convergence speed, but introduces a hyperparameter.</li></ul><ul id="ba269296-b245-4fa7-9424-d069a492456c" class="bulleted-list"><li style="list-style-type:disc"><strong>AdaGrad:</strong> Sensitive to small but important parameters, but slows down near convergence.</li></ul><ul id="30813045-3d29-4c41-bdde-261eb4f7c05c" class="bulleted-list"><li style="list-style-type:disc"><strong>RMSProp:</strong> Better for non-convex landscapes; prevents the learning rate from decreasing too quickly, but convergence is not guaranteed.</li></ul><ul id="9eb43563-9732-4dbc-ba82-7d59f957f66e" class="bulleted-list"><li style="list-style-type:disc"><strong>Adam:</strong> Handles initial steps effectively and converges earlier; adapts learning rates based on past gradients, taking smaller steps in regions of high variance, larger steps in flat regions towards a global minimum.</li></ul></details></li></ul></div></figure><hr id="1602e7d3-01e5-8090-9e74-c12f40e50d76"/><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="15e2e7d3-01e5-80cc-aba3-f5e7c676b055"><div style="font-size:1.5em"><img class="icon" src="https://www.notion.so/icons/exclamation-mark_gray.svg"/></div><div style="width:100%"><p id="d75448dc-ed6c-4eab-af54-ca9034176ce9" class=""><strong>Gradient Contour graph</strong></p><p id="15e2e7d3-01e5-8078-b1d4-d30934e9e7c8" class="">lines/colors indicate regions where the gradient value is the same. </p></div></figure><figure id="15e2e7d3-01e5-809c-9302-c64527eeb2c5" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.10.19.png"><img style="width:583.9981079101562px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.10.19.png"/></a></figure><p id="15e2e7d3-01e5-800a-b7d3-c80bd8e26fb6" class="">All these specialized NN’s are hard to optimize </p><figure id="15e2e7d3-01e5-806f-a513-f5c23e893962" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.11.55.png"><img style="width:288px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.11.55.png"/></a></figure><ol type="1" id="15e2e7d3-01e5-8022-813b-f8c84c97e859" class="numbered-list" start="1"><li>Non convex objectives</li></ol><ol type="1" id="15e2e7d3-01e5-804d-833a-c5c0790a04e6" class="numbered-list" start="2"><li>zig-zag from high loss to low loss ⇒ inefficient</li></ol><figure id="15e2e7d3-01e5-80b5-b5a4-eae456d26fe6" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.15.14.png"><img style="width:480px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.15.14.png"/></a><figcaption>A. We first looked at batch gradient descent (over the whole dataset). b) then we estimated this with stochastic gradient descent (smaller, randomly chosen batches), which should on avg. (black line) be similar. c) The loss landscape migth be rugged, so in any direction we could be going up, down, etc (zig-zag from high loss to low loss ⇒ inefficient)</figcaption></figure><ol type="1" id="15e2e7d3-01e5-8084-8217-db5bb5cc91c3" class="numbered-list" start="3"><li>Complicated Gradients </li></ol><hr id="15e2e7d3-01e5-803e-95f7-cfc09c195158"/><figure id="15e2e7d3-01e5-8082-b31b-e80922733ec4" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.19.54.png"><img style="width:2818px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.19.54.png"/></a></figure><hr id="15e2e7d3-01e5-80aa-8f48-db34e13ac431"/><p id="15e2e7d3-01e5-804a-819d-cca8ce6834b9" class="">Initial parameters we pick ⇒ what minimum we end up at. </p><p id="15e2e7d3-01e5-8001-a939-c2174f065c9e" class="">Can’t just guess the init. params that gets us to a global min. </p><p id="15e2e7d3-01e5-80a9-8032-de634f4d40c3" class="">But can choose them such that they break symmetry</p><figure id="15e2e7d3-01e5-80ae-93f9-f8718e36d21c" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.25.00.png"><img style="width:583.9981079101562px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.25.00.png"/></a></figure><p id="15e2e7d3-01e5-80f6-9247-ea930a40cddb" class="">Same weights ⇒ its as if we only had 1 hidden layer. </p><p id="15e2e7d3-01e5-80a8-9b86-dc3db9d73f05" class="">If we pick them randomly, from what distribution? What scale? </p><figure id="15e2e7d3-01e5-80c5-b829-ca46d4b0fa3e" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.30.23.png"><img style="width:432px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.30.23.png"/></a><figcaption>tradeoffs</figcaption></figure><h3 id="15e2e7d3-01e5-8005-a369-e95d928d5559" class="">Xavier Initialization </h3><ul id="15e2e7d3-01e5-80ac-b2f2-d1b8c1645bbb" class="bulleted-list"><li style="list-style-type:disc">Draw the weights from a gaussian (or normal) distribution. What parameters to use? here were solving for the variance of the distribution that will <strong>preserve the variance of activations/gradients between layers.</strong></li></ul><ul id="15e2e7d3-01e5-8039-a9cc-cd2c95912ddb" class="bulleted-list"><li style="list-style-type:disc">why? helps maintain balance flow both forward and backwards through the layers (to avoid vanishing &amp; exploding gradients across layers) </li></ul><figure id="15e2e7d3-01e5-8018-9a97-cb473721a1f8" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.34.38.png"><img style="width:2806px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.34.38.png"/></a></figure><figure id="15e2e7d3-01e5-8091-a8ab-fba1c31f4dd5" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.38.14.png"><img style="width:583.9935302734375px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.38.14.png"/></a><figcaption>5 layers. top-left: </figcaption></figure><ul id="15e2e7d3-01e5-809d-96d1-d60875a72257" class="bulleted-list"><li style="list-style-type:disc">standard initilization: <ul id="15e2e7d3-01e5-8089-ac35-ff48f2fc6b9d" class="bulleted-list"><li style="list-style-type:circle">(activations explode) when going forward (top-left)</li></ul><ul id="15e2e7d3-01e5-8041-9a72-fb4b60b1aa2f" class="bulleted-list"><li style="list-style-type:circle">(vanishing gradients) when going backwards (top-right)</li></ul></li></ul><ul id="15e2e7d3-01e5-804c-a97c-ec99daa55bc5" class="bulleted-list"><li style="list-style-type:disc">xavier: <ul id="15e2e7d3-01e5-80bc-a6d3-c1d5b335b68c" class="bulleted-list"><li style="list-style-type:circle">activations are stable across layers</li></ul></li></ul><h3 id="15e2e7d3-01e5-8040-a92d-f7de2e18fb2e" class="">Bias Initialization</h3><ul id="15e2e7d3-01e5-80de-8c32-ea323b178645" class="bulleted-list"><li style="list-style-type:disc">(typically) zero for hidden layers </li></ul><ul id="15e2e7d3-01e5-8011-867e-e0b4aa45e2ac" class="bulleted-list"><li style="list-style-type:disc">output layer: depends on data <ul id="15e2e7d3-01e5-8073-9950-f1da41cb4ce7" class="bulleted-list"><li style="list-style-type:circle">e.g. if you know one class is most common, put a bias towards it in the output. </li></ul></li></ul><p id="15e2e7d3-01e5-80d5-8ae6-de423377b2b9" class="">There are many other initialization methods (won’t cover)</p><hr id="15e2e7d3-01e5-8021-ad1d-f3122cf743f5"/><h2 id="15e2e7d3-01e5-8080-9023-d8d9cb5db9dd" class="">Traverse the Loss Landscape More Efficiently</h2><p id="15e2e7d3-01e5-808c-85d7-dc1e1ff1c0ae" class="">Stochastic gradient descent problems: </p><ul id="15e2e7d3-01e5-804c-a050-ddee1dae2833" class="bulleted-list"><li style="list-style-type:disc">small step-size: steady convergence BUT slow </li></ul><ul id="15e2e7d3-01e5-8078-98bc-f66dfc9a37af" class="bulleted-list"><li style="list-style-type:disc">large step-size: zig-zag to convergence (could overshoot) ⇒ slower convergence</li></ul><figure id="15e2e7d3-01e5-801d-b8b8-dd79538ab707" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.47.28.png"><img style="width:192px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.47.28.png"/></a></figure><h3 id="15e2e7d3-01e5-8018-8bb6-fe39385cedc0" class="">Momentum</h3><p id="15e2e7d3-01e5-8023-9b3b-deff547759a2" class="">Tries to optimize the tradeoff between <strong>stability ↔ convergence speed</strong></p><ul id="15e2e7d3-01e5-80a0-9782-c3e95e67836d" class="bulleted-list"><li style="list-style-type:disc">Continue to move in the direction you have moved in the past (ie: you have some inertia). </li></ul><ul id="15e2e7d3-01e5-80ef-9e96-d44516636703" class="bulleted-list"><li style="list-style-type:disc">Helps <strong>reduce zig-zagging</strong>: Large fluctuations will cancel each other out over time, small steady progress will accumulate velocity. </li></ul><figure id="15e2e7d3-01e5-80ea-9329-c98152b543df" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.50.26.png"><img style="width:480px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.50.26.png"/></a><figcaption>velocity at time <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span> depends on current gradient as well as the past (controlled by <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span><span>﻿</span></span>)</figcaption></figure><ul id="15e2e7d3-01e5-80e0-880a-d2862e98e3d2" class="bulleted-list"><li style="list-style-type:disc">more recent gradient ⇒ larger influence (exponenitial decay) </li></ul><figure id="15e2e7d3-01e5-80ec-a04d-d3f2a6042c64" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.55.05.png"><img style="width:432px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_22.55.05.png"/></a></figure><p id="15e2e7d3-01e5-80c4-91ba-d7f04c3d79c3" class="">Problem: adds (yet) another hyperparameter, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span><span>﻿</span></span></p><h3 id="15e2e7d3-01e5-8026-98c8-cc842604fd7b" class="">AdaGrad</h3><p id="15e2e7d3-01e5-8055-a7b5-ee29a033d910" class="">Adaptive learning rate for each parameter (according to its own history; so its like momentum for each parameter).</p><p id="15e2e7d3-01e5-8049-b4e5-d91f2b862d9e" class=""><strong>Why would you want this? </strong></p><ul id="15e2e7d3-01e5-80c2-b750-c206eba7ca63" class="bulleted-list"><li style="list-style-type:disc">In earlier laters, gradient is smaller than in later layers. </li></ul><ul id="15e2e7d3-01e5-80a5-9f21-fb77595dbdfe" class="bulleted-list"><li style="list-style-type:disc">Not all layers (and hence, there parameters) have equal number of inputs (# weights), and hence, the gradients will likely have different scales. </li></ul><ul id="15e2e7d3-01e5-8000-9b06-c6329de2af86" class="bulleted-list"><li style="list-style-type:disc">So, want optimization sensitive to each parameter</li></ul><p id="15e2e7d3-01e5-8004-b12d-e98a7bd50e1d" class="">
</p><figure id="15e2e7d3-01e5-8095-b150-dbed53fe2162" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.00.33.png"><img style="width:583.9981079101562px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.00.33.png"/></a><figcaption><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mrow><mi>t</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">g_{t,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> — gradient of <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">jth</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span><span>﻿</span></span> parameter at time <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span> </figcaption></figure><ul id="15e2e7d3-01e5-804d-b844-da2fcc373ccb" class="bulleted-list"><li style="list-style-type:disc">if a parameter is frequently large, its learn-rate decreases. </li></ul><ul id="15e2e7d3-01e5-8012-ad78-c5e3c181c667" class="bulleted-list"><li style="list-style-type:disc"><strong>sensitive</strong> to small but important parameters (those that change frequently) ⇒ sensitive to parameters that contribute most to loss. </li></ul><p id="15e2e7d3-01e5-806b-86ef-e8b211f3bc0e" class=""><strong>Problem: </strong>slows down near convergence (fast learn-rate decay) </p><ul id="15e2e7d3-01e5-8080-8c48-fef9859827e0" class="bulleted-list"><li style="list-style-type:disc">this is because denominator (sum) grows too big </li></ul><h3 id="15e2e7d3-01e5-804b-b695-d3883ba37c6f" class="">RMS Prop </h3><p id="15e2e7d3-01e5-80fe-b50c-d03c65388092" class="">Prevents the learn-rate from getting too small too quick, which will (hopefully) let it converge quicker (but not guaranteed to converge). </p><ul id="15e2e7d3-01e5-8044-97d3-fe93baa32949" class="bulleted-list"><li style="list-style-type:disc">Better for non-convex landscapes</li></ul><ul id="15e2e7d3-01e5-80a0-9dbf-df1fd6f5272b" class="bulleted-list"><li style="list-style-type:disc">Prevents old weights from contributing too highly to the sum<ul id="15e2e7d3-01e5-80e3-b0dc-c7bb0f359f31" class="bulleted-list"><li style="list-style-type:circle">discards old values from contributing to highly to sum</li></ul></li></ul><figure id="15e2e7d3-01e5-805a-91d7-dad1bdc9a5d8" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.04.31.png"><img style="width:480px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.04.31.png"/></a><figcaption>on the right, where adagrad might come to a halt before it finds the global-min, RMS has a better chance of continuing until it finds it. </figcaption></figure><h2 id="15e2e7d3-01e5-80fb-849c-fd9b24c76f9f" class="">Adam Optimizer</h2><p id="15e2e7d3-01e5-8096-a687-c3f915f0ec71" class="">Adaptive Moment Estimator</p><ul id="15e2e7d3-01e5-808f-bd8d-c5458f5eef25" class="bulleted-list"><li style="list-style-type:disc">uses gradient to estimate both: <ul id="15e2e7d3-01e5-80e6-8545-d16b95f4c55c" class="bulleted-list"><li style="list-style-type:circle">mometum (first moment), and </li></ul><ul id="15e2e7d3-01e5-80d2-8ab3-c26dd39f8a19" class="bulleted-list"><li style="list-style-type:circle">variance (2nd moment)</li></ul></li></ul><figure id="15e2e7d3-01e5-80ff-b9d3-d3745826ebe6" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.14.34.png"><img style="width:288px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.14.34.png"/></a></figure><ul id="15e2e7d3-01e5-809d-a15f-d7e23b370582" class="bulleted-list"><li style="list-style-type:disc"><link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">m_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> — first moment, <link rel="stylesheet" type="text/css" href="../../notion_styles.css"/><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> — second moment </li></ul><ul id="15e2e7d3-01e5-8021-85f3-c50a51ffcc81" class="bulleted-list"><li style="list-style-type:disc">initial bias is towards smaller values ⇒ corrected w’ Bias Correction</li></ul><ul id="15e2e7d3-01e5-80ed-95bf-c17f2ece2336" class="bulleted-list"><li style="list-style-type:disc">parameter updates converge more smoothly</li></ul><h2 id="15e2e7d3-01e5-806f-a446-c0fae95333c0" class="">Summary </h2><p id="15e2e7d3-01e5-80ba-9420-fc11a73cd109" class="">Adagrad, RMS &amp; Adam are <strong>adaptive —</strong> adjust learn-rate(s) based on magnitude of past gradients ⇒ take <strong>smaller steps</strong> in regions of<strong> high variance</strong>, larger steps in <strong>flat regions </strong>towards a global minimum</p><p id="15e2e7d3-01e5-809e-9327-cb991a2918fc" class="">Adam handles the initial steps more effectively ⇒ converges earlier.</p><figure id="15e2e7d3-01e5-8002-be4e-e8c89708e34e"><div class="source"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screen_Recording_2024-12-15_at_23.08.37.mp4">https://prod-files-secure.s3.us-west-2.amazonaws.com/21423f49-a365-4487-8460-041e9674e478/9c14dde1-6f8c-4b85-8767-3aeaed5983dd/Screen_Recording_2024-12-15_at_23.08.37.mp4</a></div></figure><figure id="15e2e7d3-01e5-8057-b333-d0f5cabfdd0c"><div class="source"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screen_Recording_2024-12-15_at_23.10.46.mp4">https://prod-files-secure.s3.us-west-2.amazonaws.com/21423f49-a365-4487-8460-041e9674e478/b2835933-fac7-4200-9262-1af0548d31cf/Screen_Recording_2024-12-15_at_23.10.46.mp4</a></div></figure><figure id="15e2e7d3-01e5-800c-a12a-eaba6a2807c2"><div class="source"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screen_Recording_2024-12-15_at_23.16.10.mp4">https://prod-files-secure.s3.us-west-2.amazonaws.com/21423f49-a365-4487-8460-041e9674e478/669ca5ba-3197-473a-8d6b-9af07601637e/Screen_Recording_2024-12-15_at_23.16.10.mp4</a></div></figure><figure id="15e2e7d3-01e5-8012-ba27-f73ab2bde6a4" class="image"><a href="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.21.09.png"><img style="width:432px" src="L17%20%E2%80%94%20Advanced%20Optimization/Screenshot_2024-12-15_at_23.21.09.png"/></a></figure></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>